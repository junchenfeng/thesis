# Selection Bias of the Exit Decision in the Pedagogical Efficacy Estimation {#engagement}

```{r env, echo=FALSE, warning=FALSE, message=FALSE}
library(ggplot2)
library(dplyr)
library(tidyr)
library(gridExtra)
proj_dir = getwd()
load(paste0(proj_dir,'/_data/02/production_data.RData'))
load(paste0(proj_dir,'/_data/02/fit_lc_data.RData'))
```

## The Optimal Practice Policy
To motivate the discussion of this chapter, consider the following problem in recommending routine learning task:

The goal is to train the learner so that their knowledge point mastery($\pi^{(i)}$) exceeds a pre-determined set of requirements ($\bar{\pi}$). The instrument is a bank of practice items with item parameter $\{s_j, g_j,\ell_j\}$. The problem is to recommend the next practice item conditions on the learner's response history. Under the assumption that the pedagogical efficacy is invariant to the number of repetition, the optimal choice is to pick the (class of) item with highest $\ell_j$.

A naive solution is to pick the item with the steepest ascending learning curve. If there is no exit decision, such naive solution is valid. However, under differential hazard rates,  the slope of the learning curve reflects both the pedagogical efficacy and the degree of dynamic selection bias. The naive optimal pick can just be a mediocre item with a really high dynamic selection bias.

An alternative way to motivate the discussion is to consider the reporting of the learner's knowledge mastery. If the hazard rate of the learned is smaller than that of the unlearned, the pedagogical efficacy(or learning rate) of the practice is (in general) biased upwards. Thus the reporting is too optimistic. 



## Exit Decision and Dynamic Selection Bias

It is a stylized fact that the learner makes different exit decision based on the response. Some of it is mechanical. For example, if the user is allowed to practice until they accumulate X errors, there is differential attrition rate after Xth practice even if the underlying hazard rate homogeneous. However, the author suspects that non-cognitive skill also drives the differential exit decision.

This most important finding of this section is that a biased learning curve is not a sufficient condition of a biased learning rate estimation. The state dependent differential hazard rate leads to bias in the pedagogical efficacy estimation.

Throughout the chapter, assume there is no effort level choice, or $E_{j,t} = 1 \quad \forall j,t$.


### Bias in Learning Curve and Bias in Learning Rate


If the exit decision is a function of $Y_t$, it can be shown that $P(Y_t|H_t=0) \neq P(Y_t)$ and $P(X_t|H_t=0) \neq P(X_t)$. The learning curve shifted upwards. There is a higher percentage of learners who master the knowledge point than that under the no exit regime. However, the Baum-Welch estimator is still unbiased because 

$$
P(X_t|H_t,Y_t) = P(X_t|Y_t)
$$
If the exit decision only depends on $Y_t$, the survival likelihood is cancelled out in calculatiing the posterior density of $X_t$. 

Here the author provides a stretch of the proof. Let $\mathbf{Y}$ be all the observed response. 

$$
\begin{aligned}
P(X_t=i|\mathbf{Y},H_t=0) &=\frac{P(X_t=i,\mathbf{Y},H_t=0)}{P(\mathbf{Y},H_t=0)} \\
&= \frac{P(H_t=0|\mathbf{Y})P(\mathbf{Y}|X_t=i)P(X_t=i)}{\sum_{k=0}^1P(H_t=0|\mathbf{Y})P(\mathbf{Y}|X_t=k)P(X_t=k)} \\
&= \frac{P(\mathbf{Y}|X_t=i)P(X_t=i)}{\sum_{k=0}^1P(\mathbf{Y}|X_t=k)P(X_t=k)} \\
&= P(X_t=i|\mathbf{Y})
\end{aligned}
$$

Similarly, it can be shown that $P(X_t=i,X_{t-1}=j|\mathbf{Y},H_t=0)=P(X_t=i,X_{t-1}=j|\mathbf{Y})$. As a result

$$
\begin{aligned}
E(\hat{\ell}) &= \frac{\sum_{t=1}^TE_{\mathbf{Y}}P(X_t=1,X_{t-1}=0,H_t=0|\mathbf{Y})}{\sum_{t=1}^TE_{\mathbf{Y}}P(X_{t-1}=0,H_t=0|\mathbf{Y})}\\
&=\frac{\sum_{t=1}^TE_{\mathbf{Y}}P(X_t=1,X_{t-1}=0|\mathbf{Y})}{\sum_{t=1}^TE_{\mathbf{Y}}P(X_{t-1}=0|\mathbf{Y})} \\
&=\ell
\end{aligned}
$$

The intuition above premiers the following theorem (proof in Appendix 1.a):

**Theorem 1**: If the exit decision depends only on the response, the Baum-Welch estimator is not biased. 

### State Dependent Differential Hazard Rate and Bias in the Learning Rate

Using the same technique, one can prove that state dependency with differential hazard rates is a sufficient and necessary conditions for the bias in the learning rate(proof in Appendix 1.b).

**Theorem 2**: If the exit decision depends on the latent state, the Baum-Welch estimators are not biased if and only if hazard rates of each state are equal.

The dynamic selection bias usually requires heterogeneity among the agents to manifest itself. However. for the Baum-Welch estimator, bias can be produced for homogeneous learners under state-dependent attrition. The bias is likely to be aggravated if learner heterogeneity is the true data generating process. 

Unfortunately, the bias is not signed although simulation shows that if $h^1(t)<h^0(t)$, the bias is in general positive for reasonable values of slip and guess ($s<0.3$, $g<0.5$).



## Application

This section first demonstrates the bias in the estimated pedagogical efficacy under state-dependent differential hazard rate and how the general learning model corrects the bias by jointly modeling the practice persistence and the practice performance.

### Simulation

The learning rate is set as $\ell = 0.3$. the initial probability of mastery is set as $\pi = 0.4$. The slip rate is $s = 0.05$ and the guess rate is $g = 0.2$. **TODO: add the rationale for the simulation parameter choice.**


```{r,echo=FALSE, warning=FALSE, message=FALSE, fig.cap = "Hazard Rates of the Simulation", fig.align='center'}

hazard_rate = data.frame(t=seq(5), correct=seq(0.05,0.25,0.05), incorrect=seq(0.1,0.5,0.1))
long_hazard_rate = hazard_rate %>% gather(response, harzard_rate,-t)
long_hazard_rate$response = factor(long_hazard_rate$response)
qplot(data=long_hazard_rate, x=t, y = harzard_rate, geom='line', col=response) + ylab('Hazard Rate') + xlab('Number of Practice Opportunity')

```


Fit the data to a model with exit decision(Hybrid) and a model without exit decision(BKT). Figure 3.2 compares the point estimation of the Hybrid model and the BKT model to the true value. The Hybrid mitigate some of the positive bias from the dynamic selection. 

```{r,echo=FALSE, warning=FALSE, message=FALSE, fig.cap = "Estimated Learning Rate. True(Solid), BKT(Blue Dash), Hybrid(Red Dotted), Distribution of Hybrid(Dotted Dash) ", fig.align='center'}
file_path = paste0(proj_dir,'/_data/02/res/sim/incomplete_point_estimation.txt')
point_est = read.table(file_path, sep=',', col.names=c('algo','s','g','pi','l','h01','h02','h03','h04','h05','h11','h12','h13','h14','h15'))
file_path = paste0(proj_dir,'/_data/02/res/sim/true_param.txt')
true_param = read.table(file_path, sep=',', col.names=c('s','g','pi','l','h01','h02','h03','h04','h05','h11','h12','h13','h14','h15'))


file_path = paste0(proj_dir,'/_data/02/res/sim/incomplete_mcmc_survival_parameter_chain.txt')
mcmc_survive_chains = read.table(file_path, sep=',', col.names=c('s','g','pi','l','h01','h02','h03','h04','h05','h11','h12','h13','h14','h15'))
mcmc_survive_chains$t = seq(10000)
mcmc_survive_sample_chains = mcmc_survive_chains %>% filter(t>5000) %>% filter(t%%10==0)



ggplot(data=mcmc_survive_sample_chains,aes(x=l)) + geom_density(linetype=4)+
    geom_vline(xintercept = point_est$l[point_est$algo=='em'], colour="blue", linetype = "longdash") + 
    geom_vline(xintercept = point_est$l[point_est$algo=='mcmc_s'], colour="red", linetype = "dotted") + 
    geom_vline(xintercept=true_param$l) + ggtitle('learning rate')


```



Another way to evaluate the model performance is to compare the learning curve of no exit($P(Y_t=1|H_t=0)$). The true learning curve and the fitted learning curves are plotted in Figure 3.3. 

```{r,echo=FALSE, warning=FALSE, message=FALSE, fig.cap = "True and Fitted Learning Curves(Hybrid=model with exit, BKT=model without exit)", fig.align='center'}

update_mastery <- function(mastery, learn_rate){
  return (mastery + (1-mastery)*learn_rate)
} 

compute_success_rate <- function(slip, guess, mastery){
  return ( guess*(1-mastery) + (1-slip)*mastery )
}

generate_learning_curve <- function(slip, guess, init_mastery, learn_rate, Tl){
  p = init_mastery
  lc = data.frame(t= seq(1,Tl), ypct = as.numeric(0), xpct=as.numeric(0) )
  
    lc$ypct[1] = compute_success_rate(slip, guess, p)
    lc$xpct[1] = p
    
    for (t in seq(2,Tl)){
        p = update_mastery(p,learn_rate)
        lc$ypct[t] = compute_success_rate(slip, guess, p)     
        lc$xpct[t] = p
    }
    return(lc)
}




true_lc = generate_learning_curve(true_param$s, true_param$g, true_param$pi,true_param$l, 5)
true_lc$type = 'True'

bkt_lc = generate_learning_curve(point_est$s[1], point_est$g[1], point_est$pi[1], point_est$l[1], 5)
hybrid_lc = generate_learning_curve(point_est$s[2], point_est$g[2], point_est$pi[2], point_est$l[2], 5)
bkt_lc$type = 'BKT'
hybrid_lc$type = 'Hybrid'

lc_data = rbind(true_lc, bkt_lc, hybrid_lc)


lc_data$type = factor(lc_data$type)
qplot(data=lc_data, x=t,y=ypct,col=type, linetype=type, geom='line') + ggtitle('Conditional Learning Curves - P(Yt=1|Ht=0)') + ylab('Success Rate') + xlab('Number of Practice Opportunity')



```




### Real Dataset
To examine the performance of the hybrid model in practice, this chapter uses the data from a Chinese online learning service provider.

The data are collected from December 2015 and January 2016 in China. The target learners are mainly first-grade, second-grade, and third-grade schoolchildren. The demographics of the learner population are unknown beyond the grade distribution. The practices are supplemental learning materials that the students can play on their own initiative. There is no material punishment for low performance or an early exit.


The data are collected from a gamified learning environment, framed as a turn-based game. Each turn, the learner answers a quiz. If he responds correctly, he is rewarded with a small amount of in-game currency; If else, he takes a damage. The game continues until the Health Point of the player drops to zero or the learner chooses to quit. The learner can withstand three or four errors before he is forced to quit. A screenshot of the interface is shown in figure 3.3

<center>![Figure 3.3: The Gamified Learning Interface](fig/app.png)</center>


Each practice sequence trains ONE knowledge point but with different question forms. For example, if the knowledge point is "Two digit minus one digit", the item can be "13-9" or "37-6". The items can be essentially viewed as identical. **TODO:Check the observed success rate**. For each knowledge point, there are sizable but finite items in the question bank. If the learner practices long enough to exhaust the question bank, he encounters questions from the past. 

This chapter chooses three representative knowledge points out of more than 200 candidates:  sequential order within 5(grade 1), two digit number minus one digit number(grade 2) and vertical division(grade 3). Appendix 2 details the data cleaning process. The two items represent "slow learning" and "fast learning" judged by the learning curve.


The observed (unconditional) learning curves are plotted as the following:

```{r, echo=FALSE, warning=FALSE, message=FALSE, fig.cap = "Empirical Learning Curves of Different Knowledge Points", fig.align='center'}

kpids =  c('2','138')
kp_names = c('Sequential Order','Vertical Division')
for (i in seq(2)){
    file_path = paste0(proj_dir,'/_data/02/spell_data_',kpids[i],'.csv')
    tmp_data = read.csv(file_path, col.names=c('spell_id','t','atag','idx'),header=F)  
    tmp_data$kpid = kpids[i]
    if (i==1){
        spell_data = tmp_data
    }else{
        spell_data = rbind(spell_data, tmp_data)
    }
}

spell_data$knowlege_point = factor(spell_data$kpid, labels=c('Vertical Division', 'Sequential Order'))

lc_plot = spell_data %>% group_by(knowlege_point, t) %>% summarize(pct=mean(atag)) %>% filter(t<=5)

qplot(data=lc_plot , x=t, y=pct, geom='line', col=knowlege_point, linetype=knowlege_point) + ggtitle('Observed Learning Curve') + ylab('Success Rate') + xlab('Number of Practice Opportunity')

```

The hazard rate curve is plotted as the following. The hazard rate curves for sequential order and two digit subtraction are not very different but the hazard rates are very different for the vertical division.

```{r, echo=FALSE, warning=FALSE, message=FALSE, fig.cap = "Empirical Hazard Rates of Different Knowledge Points", fig.align='center'}
#Check the hazard rate
#There is significant difference for item 138. Not so much for other items
imputate_hazard_rate <- function(test_data, Tmax){
  harzard_rate_data = data.frame(t=seq(1,Tmax), hr=as.numeric(0), correct = as.numeric(0), incorrect = as.numeric(0))
  for (t in seq(1,Tmax)){
    base_num = sum(test_data$t==t)
    exit_num = sum(test_data$t==t & test_data$idx==1)
    base_yes_num = sum(test_data$t==t & test_data$atag==1)
    base_no_num = sum(test_data$t==t & test_data$atag==0)
    exit_yes_num = sum(test_data$t==t & test_data$atag==1 & test_data$idx==1)
    exit_no_num =  sum(test_data$t==t & test_data$atag==0 & test_data$idx==1)
    harzard_rate_data[t,] = c(t, exit_num/base_num, exit_yes_num/base_yes_num, exit_no_num/base_no_num)
  }
  harzard_rate_data =  harzard_rate_data %>% select(t,correct,incorrect) %>% gather(res,hr,-t)
  return(harzard_rate_data)
}


test_data = spell_data %>% filter(kpid==2)
hr_data = imputate_hazard_rate(test_data, 5)
hr_data$res = factor(hr_data$res)
h1=qplot(data=hr_data, x=t, y=hr, col=res, linetype=res, geom='line') + ylab('Hazard Rate') + 
  theme(axis.text.x=element_blank(),
        axis.title.x=element_blank(),
        axis.ticks.x=element_blank())

test_data = spell_data %>% filter(kpid==138)
hr_data = imputate_hazard_rate(test_data, 5)
hr_data$res = factor(hr_data$res)
h2=qplot(data=hr_data, x=t, y=hr, col=res, linetype=res, geom='line') + ylab('Hazard Rate') + xlab('Number of Practice Opportunity')

grid.arrange(h1, h2, ncol=1)

```

### Compare the Learning Curves

The learning rate estimated by the hybrid model is way smaller than that of the classical BKT model. 

|Knowledge Point | BKT | Hybrid|
|----------------|-----|-------|
|Sequential Order| 0.213|0.097 |
|Vertical Division|0.077 |0.004 |

As a result, the latent learning curve of the hybrid model is much flatter than that of the classical BKT model. However, after adjusting for the hazard rate, the observed response curve of the hybrid model is closer to the shape of the observed learning curve. The difference is especially astounding for the vertical division where the differential hazard rates are more profound.
 

```{r, echo=FALSE, warning=FALSE, message=FALSE, fig.cap = "Empirical and Fitted Learning Curves", fig.align='center'}

impute_x_hazard <-function(pi,h0,h1){
  return(pi*(1-h1)/(pi*(1-h1)+(1-pi)*(1-h0)))
}

generate_learning_curve_hazard<-function(slip,guess,pi,learn_rate,h0_vec,h1_vec,Tl){
  p = pi
  lc = data.frame(t= seq(1,Tl), ypct = as.numeric(0), xpct=as.numeric(0) )
  lc$ypct[1] = compute_success_rate(slip, guess, p)
  lc$xpct[1] = p
  for (t in seq(2,Tl)){
    # impute the posterior density of x
    p_post = impute_x_hazard(p, h0_vec[t], h1_vec[t])
    p = update_mastery(p_post,learn_rate)
    lc$ypct[t] = compute_success_rate(slip, guess, p)     
    lc$xpct[t] = p
  }  
  return(lc)
}



for (i in seq(2)){
    file_path = paste0(proj_dir,'/_data/02/res/',kpids[i],'/full_point_estimation.txt')
    param_data = read.table(file_path, col.names=c('algo','s','g','pi','l','h01','h02','h03','h04','h05','h11','h12','h13','h14','h15'), header=F,sep=',') 
    
    bkt_lc = generate_learning_curve(param_data[1,2], param_data[1,3], param_data[1,4], param_data[1,5], 5)
    h0_vec = c(param_data[2,6],param_data[2,7],param_data[2,8],param_data[2,9],param_data[2,10])
    h1_vec = c(param_data[2,11],param_data[2,12],param_data[2,13],param_data[2,14],param_data[2,15])
    hybrid_observ_lc = generate_learning_curve_hazard(param_data[2,2], param_data[2,3], param_data[2,4], param_data[2,5], h0_vec, h1_vec, 5)
    hybrid_latent_lc = generate_learning_curve(param_data[2,2], param_data[2,3], param_data[2,4], param_data[2,5], 5)

    tmp_data = data.frame(t=seq(5))
    tmp_data$Empirical = lc_plot$pct[lc_plot$knowlege_point==kp_names[i]]
    tmp_data$BKT = bkt_lc$ypct
    tmp_data$HybridLatent = hybrid_latent_lc$ypct
    tmp_data$HybridObserv = hybrid_observ_lc$ypct
    tmp_data = tmp_data %>% gather(algo, pct, -t)
    tmp_data$kpname =kp_names[i]
    
    if(i==1){
      lc_data = tmp_data
    }else{
      lc_data = rbind(tmp_data, lc_data)
    }
}
lc_data$algo=factor(lc_data$algo)

qplot(data=lc_data, x=t, y=pct, geom='line', col=algo, linetype=algo, facets=.~kpname) + ylab('Success Rate') + xlab('Number of Practice Opportunities')

```

## Discussion and Future Work
### Hot Streak Effect
If the user is on a winning streak, they are less likely to stop. Consequently the each response is not independent and cannot directly apply the product rule. 

The "streak" (or sequence) dependence a testable hypothesis. Under the assumption of independent response sequence, the probability of termination is only a function of item characteristics. The probability distribution of termination shall be identical, conditioning on the preceding answer sequence, a direct application of the definition of statistical independence.

Figure 3 shows the (2nd) easiest case of sequence dependence. Conditioning on the answer sequence of last 2 items (2-item sequence), whether the user gets it right or wrong influences the termination of a spell. The left panel shows the pdf of termination probability for the wrong answer while the right panel that of the right answer. Four numbers differentiate the previous answer patterns: 0 stands for two wrong, 1 for first wrong and second right, 10 for first right and second wrong, 11 for both right.

There are two interesting observations from this figure:
    
(1) If the current answer is wrong, the data generating process is close to sequence independence, with two winning streaks slightly increases the chance of keep practicing.

(2) If the current answer is right, the data generating process is sequence dependent, especially for 3 wins in a row, with the rest scenario close to sequence independent.

A similar pattern can be found for 3-item sequence or 4 item sequence.

The caveat of such exploratory analysis is a selection process. Group the data by the triplet of items, retain the group that has more than 400 data points. Then group those retain triplets by a combination of the current and previous responses, retain those triplets that have data in all 8 possible combinations. After the two-step filtering, only 215 item triplets remains, accounting for around 60% of the total response data.
```{r, echo=FALSE, warning=FALSE, message=FALSE, fig.cap = "Hot Streak Effect", fig.align='center'}
fig_3_data$streak_id = factor(fig_3_data$streak_id)
qplot(data=fig_3_data, x=pct, col=streak_id, linetype=streak_id,geom='density', facets=.~ans_tag) + xlab('Conditional Hazard Rate')
```

### user Heterogeneity

The key insight of this chapter is that selection bias does influence parameter estimate. However, the basis for latent knowledge modeling may be too strong. Bayesian Knowledge Tracing model makes a very strong assumption about the process which is unlikely to be met in reality. Duolingo[@streeter2015mixture] proposes a nonparametric mixture model to replace the BKT, which claims to have superior empirical performance. Mixture model can be implemented in MCMC by data augmentation scheme and it may help to solve the identification problem of the mixture learning curve model as well.


## Appendix



### 1. Proof of Theorem 1

If the classical BKT setting is true, $\ell, s, g$ can be estimated from any two consecutive practice sequences. Therefore, it is sufficient to prove that the classical BKT model is biased when $T=2$.

If the estimator is unbiased, the parameter converges to the true value. In another words, if $\hat{\Theta}^{n}=\Theta$, the next iteration follows $\hat{\Theta}^{n+1}=\Theta$.  

Let $P(i,j|\Theta) = P(Y_{t-1}=i,Y_t=j|\Theta)$. The $\gamma$ and $\xi$ from the Baum-Welch estimator can be written as 

$$
\begin{aligned}
\gamma(i,j,\hat{\Theta}) &= \frac{(1-\hat{\pi})P(Y_1=i,X_1=0)[(1-\hat{\ell} P(Y_2=j,X_2=0)+\hat{\ell} P(Y_2=i,X_2=1))]}{P(Y_1=i,Y_2=j,\hat{\Theta})}\\
\xi(i,j,\hat{\Theta}) &= \frac{(1-\hat{\pi})P(Y_1=i,X_1=0)\hat{\ell} P(Y_2=j,X_2=1)}{P(Y_1=i,Y_2=j,\hat{\Theta})}\\
\end{aligned}
$$
Let $Y_t^k$ be the reponse of leaner $k$ at sequence $t$. The next iteration of the $\ell$ is 

$$
\begin{aligned}
\hat{\ell}^{n+1} &= \frac{\sum_{k=1}^NI(Y_1=Y_1^k,Y_2=Y_2^k,H=0)\gamma(Y_1^k,Y_2^k,\hat{\Theta}^n)}{\sum_{i=0}^1\sum_{j=0}^1I(Y_1=Y_1^k,Y_2=Y_2^k,H=0)\xi(Y_1^k,Y_2^k,\hat{\Theta}^n)}\\
                 &=  \frac{\sum_{i=0}^1\sum_{j=0}^1\frac{\sum_{k=1}^NI(Y_1^k=i,Y^k_2=j,H=0)}{N}\gamma(i,j,\hat{\Theta}^n)}{\sum_{i=0}^1\sum_{j=0}^1\frac{\sum_{k=1}^NI(Y_1^k=i,Y^k_2=j,H=0)}{N}\xi(i,j,\hat{\Theta}^n)}
\end{aligned}
$$

By law of large numbers $\lim_{N\rightarrow \infty}\frac{\sum_{k=1}^NI(Y_1^k=i,Y^k_2=j,H=0)}{N} \rightarrow P(Y_1=i,Y_2=j,H=0)$. Thus 

$$
\begin{aligned}
\lim_{N\rightarrow \infty}\hat{\ell}^{n+1} \rightarrow \frac{\sum_{i=0}^1\sum_{j=0}^1P(Y_1=i,Y_2=j,H=0)\gamma(i,j,\hat{\Theta}^n)}{\sum_{i=0}^1\sum_{j=0}^1P(Y_1=i,Y_2=j,H=0)\xi(i,j,\hat{\Theta}^n)}
\end{aligned}
$$

#### a.Theorem 1

If $H=f(Y_1)$, it can be shown that $P(Y_1=i,Y_2=j,H=0) = (1-h(i))P(i,j)$.  Let $\hat{\Theta}^n=\Theta$

$$
\begin{aligned}
\lim_{N\rightarrow \infty}\hat{\ell}^{n+1} &\rightarrow \frac{[1-h(0)]\sum_{j=0}^1P(0,j)\xi(0,j,\Theta)+[1-h(0)]\sum_{j=0}^1P(1,j)\xi(1,j,\Theta)}{[1-h(0)]\sum_{j=0}^1P(0,j)\gamma(0,j,\Theta)+[1-h(1)]\sum_{j=0}^1P(1,j)\gamma(1,j,\Theta)}\\
&=\frac{(1-\pi)[(1-h(1))g+(1-h(0))(1-g)]\ell}{(1-\pi)[(1-h(1))g+(1-h(0))(1-g)]}\\
&= \ell
\end{aligned}
$$
Thus concludes the proof of theroem 1.

#### b.Theorem 2


If $H=f(X_1)$, can be shown that $P(Y_1=i,Y_2=j,H=0) = [1-h(1)]P(Y_1=i,Y_2=j)+[h(1)-h(0)]\gamma(i,j,\Theta)$. Let $\hat{\Theta}^n=\Theta$. It can be shown that 

$$
\lim_{N\rightarrow \infty}\hat{\ell}^{n+1} 
\rightarrow \frac{\sum_{i}\sum_{j}[1-h(1)]P(i,j)\xi(i,j,\Theta) + [h(1)-h(0)]\xi(i,j,\Theta)\gamma(i,j,\Theta)}{\sum_{i}\sum_{j}[1-h(1)]P(i,j)\gamma(i,j,\Theta)+[h(1)-h(0)]\gamma(i,j,\Theta)^2}
$$

It is easy to show that $\lim_{N\rightarrow \infty}\hat{\ell}^{n+1} \rightarrow \ell$ if and only if $h(1)=h(0)$. Therefore, the parameter only converges to the true value if there is no differential attrition depends on state. Thus concludes the proof of theroem 2.





### Appendix 2: Data Cleaning Process
The study collected more than 68 million exercise logs. 

First retain serious learners, defined as those have more than 50 log entries, accounting for 20% of the total learners. However, serious learners generated 42 million exercises log or 62% of the total logs.

The recommendation algorithm is designed as much that the knowledge points alternate between different practice sequences so that the learner is not bored. Therefore, there are two sequence ranks one can compute. The global sequence rank ignores the interval and continues the practice rank count over the whole sample period. The local sequence rank only counts the practice rank within the sequence. Neither counting method is perfect. The global sequence rank completely ignores the dropout; while the local sequence rank violates the assumption of homogeneous initial mastery. For the purpose of this chapter, learner heterogeneity is a lesser evil so the local sequence rank is chosen.

The three knowledge points all have more than 200,000 practice logs. Other than the vertical division, 95% of the practice sequences have a life span smaller than 5 periods. For vertical division, 85% of the sequences ends before the sixth practice. 

Take a 2% random sample from the log repository of each knowledge points for parameter estimation and 1% random sample for the out sample forecast. The vertical division has a smaller sample size thus the percentages for in-sample and out-sample are 4% and 2% respectively. 
