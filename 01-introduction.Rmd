---
output:
  pdf_document: default
  html_document: default
---

```{r, echo=FALSE}
library(knitr)
proj_dir = getwd()
```

# Introduction {#intro}

Learning through practices, or learning by doing, is an important mode of learning. Practice, according to Merriam-Webster, means "to do something again and again in order to become better at it". Although repetition is a necessary condition for mastery, it is not a sufficient one. This thesis attempts to quantify the efficacy of the practice in order to further the understanding of what to practice, how to practice and when to practice. 

## Mastery, Learning, and Practice Efficacy

This thesis defines the mastery as the capability to solve a  problem or perform a task in a particular domain. Although the definition does not exclude transferable skill or creativity, this thesis focuses on the muscle memory aspect of the mastery: the ability to solve similar problems. For example, the mastery of solving two-variable equations requires the learner be able to solve any linear equations with two unknowns in algebra format. However, it does not guarantee that learner can recognize the price-quantity equilibrium a one-good linear supply and demand market system is a solution to linear equations with two unknowns. Further, the notion of "capability" implies that the mastery is a conceptual construction not directly observable. The observed response to the problem is a noisy measure of the true mastery. An unmastered learner can solve the problem by good luck while a mastered learner may fail due to bad luck. Because the mastery is unobserved, it must be inferred from the observed solution to the problem.

The concept of learning is defined as a process that the learners enable themselves to solve a problem that they previously were unable to. Although there are other formats of learning than problem-solving, self-reflection on previous mistakes, for example, problem-solving is a common format of learning and the interest of this thesis. Practice is defined as a sequence of problems to solve or tasks to perform. The notion of "sequence" emphasizes the repetitive nature of practice, which is echoed in Merriam-Webster's definition. The old idiom "practice makes perfect" still rings true. Repetitive practice is the cornerstone of expertise of many professions[@ericsson1993role], be it in sports, arts or science. The bad reputation of "teach to the test" is a result of the misguided construction of mastery. If the test authentically represents the problems the students need to solve in order to be successful, teaching to the test is a good thing rather than a bad thing. This thesis will not venture to discuss how the mastery shall be defined, but rather to discuss how to study the impact of practice learning given a pre-defined mastery and a set of problems.

To characterize learning, it is necessary not only to characterize the current status of the mastery but also the change of the mastery. Had the responses been a perfect signal of the mastery, the characterization would have been an easy task. Unfortunately, the observed response is only a noisy measure. Consider the simple case that the learner solves two problems, failed the first time while successful the second time. If the response perfectly reveals the mastery status, one can infer the learner is unmastered in the first problem but mastered in the second one. However, if the observation is a noisy measure of the mastery, one can argue the learner is unmastered and he gets lucky the second time, the learner is mastered and he gets sloppy the first time or the learner is unmastered initially but transits to mastery by learning from his first failure. All three alternatives are possible if the mastery can change during the course of the practice, while only the first two inferences stand if the mastery is assumed to be static throughout the practice. It is a subtle but critical difference between viewing the practice sequence as a static description of the current mastery and viewing it as a dynamic trajectory of the historical mastery status. 

The prevailing psychometrics literature takes the static view. The family of models derived from the item response theory(IRT) [@rasch1960probabilistic;@Carlson2013IRT] requires local independence as a fundamental identification assumption[@lord1980applications]: When conditions on the latent ability, the responses to each item are independent. Although the local independence assumption does not explicitly states that the analysis is conditioned on the same latent ability, IRT models commonly assume that is the case. Because the static view excludes the possibility of learning, the IRT models are suitable to study the process of learning by doing.

When taking the dynamic view of the mastery, instructional efficacy of the practice quantifies the capability of the problem to change the latent mastery.  The operational definition of efficacy depends on the operational definition of mastery and change. For example, if the mastery is assumed to be binary variable and the change is defined as the transition from the unmastered(0) to mastered(1), the efficacy can be defined as the probability of such a change. if the mastery is assumed to be a continuous variable and the change is defined as the increment of the mastery score, the efficacy can be defined as the magnitude of such a change. 

Instead of defining and measuring the abstract and unobserved concept of mastery, one can describe the learning as the difference between the average success rate before and after the pedagogical intervention. In the medical research literature, such measure is usually termed as effectiveness[@flay1986efficacy]. One such example is the learning gain metrics used by the Khan Academy[@faus2015systems] to evaluate the quality of its instructional video. There are practical reasons to favor the efficacy measure to the effectiveness measure. As the thesis will argue later in details, the effectiveness measure both the true efficacy of the practice and the engagement level of the learners. A lack of effectiveness can be attributed to bad practice or bad incentive for the learner to engage in the practice.  If the practice has no efficacy, the content shall be eliminated from the instructional materials. If the practice has efficacy but the user is not engaged, it may be worthwhile for the instructor (or the learning product manager) to further improve the learning incentive and learning interface. 

## The Instructor's Problem and the Dual Role of Practices

After the abstract discussion of mastery and learning, let's consider the concrete teaching scenario where an instructor interacts with a learner. The instructor assesses what the learner know and what he does not know. Based on the information, the instructor devises and executes a teaching plan. In the next loop, the instructor uses the assessment step to gather feedback on the teaching step of the last loop and improves the current teaching step upon it.The two steps consist an instruction loop that is repeated until the learner master the material. The general concept of the instructor is not limited to a human teacher. it can also be a computer algorithm or a set of practice. No matter who or what fills the role of the instructor, they shall be capable of executing the two-step loop.

This thesis focuses on the scenario that the practice is the instructor.  Therefore, the practice has dual roles: it is both the assessment tool and the instruction tool. As the assessment tool, the result of the practice is an anchor to the inference of the mastery status. As the instruction tool, the process of practice elevates the learner's mastery. Furthermore, suppose the question bank is given, the design of the practice as an instructor narrows down to the selection and the sequencing of the question items from the question bank. 

Computerized Adaptive Testing(CAT) offers a well-documented selection and sequencing strategy that adapts to the learner's individual response. CAT aims to obtain a measurement of the mastery with a pre-specified precision by the minimum number of questions. Although the underlying mathematical mechanism differs, CAT favors items that sharply differentiate student's ability in a certain region. If the learners above an ability threshold can solve the item with high certainty while those below the threshold fail it with high certainty, then the item is likely to be recommended by the CAT system to learners whose "suspected" mastery include the ability threshold. Despite being a reasonable recommendation strategy for assessment, it is intuitively an ineffective strategy for instruction because the learners below the threshold need to have a moderate chance of solving the problem through trial and error with the help of scaffoldings and hints. A good practice question can be a bad exam question. Therefore, the CAT is not the optimal solution for creating practice set as instruction.

If the instructional efficacy of the problems in the question bank is known, it is possible to develop a reasonable selection and sequencing strategy that adapts to the learner's progress. If the learners are homogeneous in their learning gain from questions, but heterogeneous in their initial mastery level, the recommended practice is similar conditional on the same mastery but different for different initial levels. If the learners are heterogeneous in the efficacy and the initial mastery level, the recommendation is more complicated but still feasible. When more responses are observed, the instructor can better identify the type of the learners and devise a learning plan accordingly. 

Therefore, a quantitative measurement of the practice efficacy is the basis of building an algorithmic practice tutor system that is capable of mimicking the human instructor. To provide a rigorous methodology for quantifying the practice efficacy is the topic of this thesis.


## The Bayesian Knowledge Tracing Model

In the learning analytics literature, the bayesian Knowledge Tracing(BKT) model is the classical representation of the dynamic learning process [@corbett1994knowledge]. The BKT model formalizes the intuition that "practice makes perfect": the learner can eventually achieve mastery by repeated exercise. The bayesian Knowledge Tracing model family is the main user modeling engine in many intelligent tutor systems(ITS), most notably the cognitive tutor[@aleven2002effective;@koedinger2006cognitive;@ritter2007cognitive] by the Carnagie Learning LLC and the ASSISTment[@pardos2010modeling] by Worcester Polytechnic Institute.

The BKT model assumes that the learner's mastery level has only two states: unmastered and mastered. The learner's initial mastery is characterized by the probability of being mastered. If the learner is unmastered, at each practice opportunity, the learner has a probability to transit from unmastered to mastered. The transition probability is called the learning rate in the literature and the instructional efficacy in this thesis.  If the learner is mastered, he never regresses on the mastery upon further practices. Because the observed response is a noisy measure of the latent mastery, te BKT model uses the guess rate to measure the probability that the learner guesses correctly when he is unmastered and the slip rate to measure the probability that the learner makes an accidental error when he is mastered. 

The Bayesian Knowledge Tracing model breeds a family of learning analytics model that deploys the same structural representation of the learning process. The main extension of the BKT model is to relax the strong learner homogeneity assumption by allowing the learner to be different in their initial mastery probability[@pardos2010modeling], the slip and guess rate[@d2008more] or the learning rate[@lee2012impact;@yudelson2013individualized]. The performance factor analysis model[@pavlik2009performance] allows for different learning based on the response by marrying the "practice make perfect" intuition from the BKT model with the logit response curve from the IRT model.  However, none of the paper exploits the possibility to relax the two-state latent assumption that rules out the possibility of reinforcement learning.


Another major research interest in the Bayesian Knowledge Tracing literature is the model identification. Beck et al first argued that the Bayesian Knowledge Tracing model is not uniquely identified[@beck2007identifiability]. They claimed that different parameter sets that have very different interpretations of the learning process result in the same learning curve, therefore the model is not identified. Their work motivates some late development of the BKT model to use the individualized parameter to solve the identification issue[@rai2009using;@d2008more;@pardos2010modeling]. Unfortunately, although Beck et al had the right empirical observation, they arrived at the wrong conclusion. In fact, the model identification of the BKT model is never properly addressed in the literature, nor is the later extension that allows for individualized parameters. 

Last but not least, the Bayesian Knowledge Tracing model makes an implicit assumption that the learner will engage in the practice with their best effort for as long as it takes. There is emerging empirical evidence from the literature that puts the intensity[@baker2004detecting;@feng2009addressing] and the duration [@murray2013revealing;@pelanek2016impact] of the engagement into question. The literature starts to realize that the lack of engagement is likely to bias the model inference, but a formal analysis on the bias condition and magnitude is still at large.

This thesis intends to address all three problems in the current Bayesian Knowledge Tracing model research: a restrictive latent model structure, a lack of formal analysis on the model identification and a lack of formal analysis of the bias caused by learner engagement.


## Preview of the Results

The second chapter lays out the general model of learning through practices(LTP). The chapter first describes the learing process without the engagement factor with a Hidden Markov Model, which admits an arbitrary number of states in the latent mastery and in the observed response. It shows that the Bayesian Knowledge Tracing model is a special case of the general learning model. It also shows that the general model can exhibit re-inforcement learning. The chapter then uses the stop decision to describe the engagement length and the effort decision to describe the engagement duration. The learning model is extended to account for the impact of these decisions on the learning dynamics. As an illustration of its expressive power, the general learning model reinterprets the Vygotsky's zone of proximal development learning theory.

he third chapter discusses the identification assumptions for the general model. By reparametrizing the general learning model as a multinomial distribution, the sample frequencies of the full joint response distributions are sufficient statistics of the system and the moment conditions for identification. It can be proved that there exits a local optimum parameter set as long as the number of the parameters are smaller than or equal to the number of moment conditions and the jacobian matrix of the moment conditions at the optimum solutin has full column rank. This necessary identification assumption puts an upper limit on the number of model parameter. In addition, the proof points out that the learning curve is not the sufficient statistics of the system and shall not be used in inference or diagnostics. In the special case of the Bayesian Knowledge Tracing model, this chapter is able to provide the sufficient and necessary identification conditions by solving the moment conditions analytically. The estimation algorithm used in this thesis also requires user homogeneity, item order exogeneity and special rank order conditions on the mapping of the states between latent mastery and the observed response to prevent label switching.

The fourth chapter describes the Monte Carlo Markov Chain algorithm to estimate the model. The MCMC routine first augments the latent states by the forward recursion backward sampling algorithm given the parameters, then uses the Gibbs sampler to update the parameters given the augmented data. In the second step, if the conditional likelihood has a conjugate prior distribution, the Gibbs sampler draws from the conjugate posterior distribution. If it does not have a conjugate prior distribution, the Gibbs sampler draws new parameters by the Adaptive Rejection Sampling. The chapter uses simulation data to demonstrate that MCMC algorithm can estimate the parameters with reasonable precision of a general learning model that have three states of latent mastery, the stop decision and the engagement decision. 

The fifth chapter applies the general learning through practice(LTP) model to analyze the dynamic selection bias of estimated efficacy due to sample attribution. Different practice sequence length is a common phenomenon in learning. This chapter shows that it is not a sufficient condition to jeopardize the parameter learning if the LTP model fails to account for the stop decision with a hazard model. If the learner exists the practice sequence based on the response, the LTP model with or without the hazard model consistently estimates the pedagogical efficacy. If the learner exists the practice sequence based on latent mastery, only the  LTP model with the hazard model consistently estimate the pedagogical efficacy. As for the posterior inference on the learner's mastery, only the LTP model with the hazard model consistently estimated the posterior probability of mastery given the observed data. The chapter applies the LTP with hazard model to a dataset of 1st and 3rd grade math learning. In that dataset, the majority of the learning gain observed in the data may be attributed to efficacy of the practice. The proportion is as low as 50% and as high as 95%. In addition, the hybrid model slightly improves the insample fitness and the outsample forecast power for learners whose practice streak longer than one shot.


The sixth chapter applies the general learning through practice(LTP) model to evaluate efficacy in low stake learning environment where measure error(i.e. frivolous wrong response) due to a lack of effort abounds. Randomized Control Trials are an important method to evaluate relative the pedagogical efficacy of different practice materials. Usually the data are analyzed with the Difference in Difference regression which measures the relative effectiveness of the practice materials. This chapter shows that the relative effectivness maynot be a monotonic function of the relative efficacy when the effort induced measurement error is present. This chapter further argues that the LTP model that accounts for state dependent effort decision correctly recovers the relative efficacy of the experimental data. The chapter applies LTP with effort model to an experiment that compares the efficacies of vocabulary scaffolding and video scaffolding in 3rd grade geometrylearning. The case study details the classification method of the measurement error and evidence of differential effort rate between different groups. Whereas the DID estimator shows no significant difference among the two treatment groups and the control group, the LTP with effort model strongly suggests that the video scaffolding has superior when controlled for effort input, which is consistent with the pedagocial expert's prior expectation. 
