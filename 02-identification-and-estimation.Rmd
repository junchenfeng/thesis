# Identification and Estimation {#estimation}

  
This chapter discusses the identification and estimation of the general learning through practices model. The first section discusses the condition for unique parameter identification from a frequentist perspective. The second section describes the Markov Chain Monte Carlo estimation method.

## Identification for Maximum Likelihood Estimation

Define identification as the following **(Greene,XXXX)**:

The parameter vector $\theta$ is identified, if for any other parameter vector $\theta^*$, for some data, $L(\theta^*|y)\neq L(\theta|y)$.

Fundamentally, identification is a frequentist concept. Only if the parameter vector is assumed to be a fixed point does "unique" identification matters. From a Baysian perspective, the parameter is a distribution and as long as the posterior distribution is proper, the inference is valid. That said, if the model is not identified, the posterior parameter distribution is multi-modal which makes MCMC convergence a practical issue. In the context of the general learning model, model identification imposes an upper limit on the model complexity, since now the number of states of the latent mastery and observed response can, in theory, takes arbitrary large values.

### User Homogeneity and Item Exogeneity

Chapter 1 describes a learning model for an individual. Because the latent state never regresses(Assumption 5), practice sequence from any individual may not exhaust all states and state transition. Therefore, the identification must be performed on the repeated observations[@rabiner1989tutorial], or on the population in this context. The critical identification assumption that rationalizes applying a model of individual learner to the population data is:

**Identification Assumption 1**: The learner's initial latent state mastery is I.I.D draw from the multinomial distribution with probability mass function $P(X_1=k)=\pi_k$.

Assumes that the item sequence is chosen exogeneously. Therefore, the item assignment is independent of the latent mastery, the responses, the effort choice, and the stop choice.

**Identification Assumption 2**: $\mathbf{A} \perp\!\!\!\perp \mathbf{Y}, \mathbf{E}, \mathbf{H}, \mathbf{X}$ 


### Label Switching

Label switching is a common problem in the mixture model. Consider a general mixture model with K components $(C_1,\dots,C_K)$, each associatd with the parameters $\theta_{C_1},\dots,\theta_{C_L}$. Because the label on the components are arbitrary without additional constraints, permutation of the labels on the components and parameters produce identical likelihood.

Rank order condition is one solution to the label switching problem. The non-regressive state assumption is not sufficient to prevent label switching, even for the two state case. The additional rank order condition requires some intuition.

When $M_X=2,M_Y=2$, it is neccesay to assume that the correct rate of mastery state is higher than that of the unmastery.

**Identification Assumption 3(a)**: $c^{1,1} \leq c^{1,2}$.

When $M_X=3,M_Y=3$, it is neccesary to assume that the lowest mastery never produces fully correct response and the highest mastery never produces fully incorrect response. The assumption imbuses the three state with practical meaning. $X_t=1$ requires intervention, $X_t=2$ requires reinforcement and $X_t=3$ requires maintanence.

**Identification Assumption 3(b)**: $c_j^{2,1}=c_j^{2,3}=0$.

### Sufficient Statistics

Because $\mathbf{Y},\mathbf{A}, \mathbf{E},\mathbf{H}$ are all discrete variables, the sample space of their joint distribution is therefore countable. Let it be $N_D$. Define a new random variable $\Omega$ whose sample space is the same as the joint distribution of $\mathbf{Y},\mathbf{A}, \mathbf{E},\mathbf{H}$. The probability mass function of $\Omega$ is 

$$
P(\Omega=\omega) = P(\mathbf{Y}=\mathbf{y},\mathbf{A}=\mathbf{a}, \mathbf{E}=\mathbf{e},\mathbf{H}=\mathbf{h})
$$

Define a mapping function $G(\mathbf{y},\mathbf{a},\mathbf{e},\mathbf{h})=\omega$. It is possible to prove (in Appendix 1) that

**Theorem 1**: $\{ n_1,\dots\,n_{N_D}\}$ are sufficient statistics of joint distribution $(\mathbf{Y},\mathbf{A}, \mathbf{E},\mathbf{H})$ where $n_\omega=\sum_{i=1}^N I(G(\mathbf{y}^i,\mathbf{a}^i,\mathbf{e}^i,\mathbf{h}^i)=\omega)$, $i$ is the learner id, and $N$ is the number of learners.


### Moment Conditions and Identifiable Parameter Number

Theorem 1 effectively provides $N_D-1$ nonlinear moment conditions for the parameter estimation, which are $\{P(\Omega=1),\dots,P(\Omega=N_d-1) \}$. Thus the parameters can be estimated, in principle, by the General Methods of Moments. The necessary condition for **local** identifications [@newey1994large] requires the number of parameters is smaller than the number of moment conditions and the Jocobian matrix at the neighborhood of the $\theta^*$ is no-degenerate. The following identification theorem essentially echoes the local identification assumption for GMM.

**Theorem 2**: The parameters are locally identified if the number of parameter is smaller or equal to $N_D-1$ and the Jocobian matrix has full column rank at $\theta^*$.

Although Theorem 2 fails to provide sufficient condition on which model specifications are identified, it at least caps the model complexity as a necessary conditions. For example, say there is a two item quiz in fixed order. Only responses are observed. What models are identifiable by this dataset? If $M_x=M_y=2$, there are only 3 moment conditions but 6 parameters to estimate. Thus the model is not identified? Under the structure of $M_x=M_y=2$ and fixed order, at least four items are required to identify all the parameters. If the order is allowed to vary, the model is possibly uniquely identified by two items because there are seven moment conditions,

### Identification of the Bayesian Knowledge Tracing Model

As a lemma to Theorem 2, it is possible to prove (in Appendix 2) that 

**Lemma 1**: The Bayesian Knowledge Tracing model is identified if at least 3 periods of responses are observed where $\pi\neq 1$, $\ell\neq1$ and $c^{1,0} \neq c^{1,1}$.

Lemma overthrows a long held belief in the learning analytics community that the parameters of the classical Bayesian Knowledge Tracing model is not uniquly identified[@beck2007identifiability;@van2013properties]. They prove that the same learning curve can be generated by different sets of parameters. Although this claim is correct, it does not imply that the underlying hidden markov process is not identified because the learning curve is not the sufficient statistics of the joint distribution of $\mathbf{Y}$.


## Estimation

This section describes the estimation of parameters by the Markov Chain Monte Carlo algorithm. Because of the lack of guarantee of global identification, The MCMC method, if converged, traverses the whole parameter space and is thus able to discover the multi-modality in the posterior distribution. The general strategy of estimating HMM with MCMC is to first augment the hidden state then update the model parameter with Gibbs sampler. 

### State Augmentation

This subsection describes two ways of augment the latent states. THe brute force algorithm calculates the likelihood of the augmented data, marginalizes over the nuance states, impute the conditional state transition probability, and draw states accordingly. In contrast, the forward recursion and backward sampling algorithm calculate the local conditional state transition probability recursively, use the first order markov chain independence to justify drawing states from the local conditional state transition probability. Both methods sample the states backward for better state mixture[@scott2002bayesian].

#### The likelihood and the Agumented likelihood
The likelihood of $(\mathbf{Y}, \mathbf{A}, \mathbf{H}, \mathbf{E})$ is sum of all augmented likelihood
$$
P(\mathbf{Y},  \mathbf{E}, \mathbf{H}, \mathbf{A}) \propto \sum_{X_1}\dots\sum_{X_{T}}P(\mathbf{Y}, \mathbf{E}, \mathbf{H}, \mathbf{X}|\mathbf{A})
$$


For a particular state augmentation , factor the likelihood according to the model

$$
\begin{aligned}
P(\mathbf{Y},  \mathbf{E}, \mathbf{H}, \mathbf{X}|\mathbf{A})
&= P(\mathbf{Y}|\mathbf{X},\mathbf{A},\mathbf{E})P(\mathbf{H}|\mathbf{X})P(\mathbf{E},\mathbf{X}|\mathbf{A})
\end{aligned}
$$

The conditional likelihood of observed response

$$
\begin{aligned}
P(\mathbf{Y}|\mathbf{X},\mathbf{E},\mathbf{A}) &= \prod_{t=1}^{T} \prod_{k=1}^{M_x}\prod_{j=1}^J[ \prod_{r=0}^{M_y-1} (c_j^{r,k})^{I(A(t)=j,Y_t=r,X_t=k,E_t=1)}\prod_{r=1}^{M_y-1}0^{I(A(t)=j,Y_t=r,X_t=k,E_t=0}]
\end{aligned}
$$
The conditional hazard rate is

$$
\begin{aligned}
P(\mathbf{H}|\mathbf{X}) &=  \prod_{t=1}^{T}\prod_{k=1}^{M_x}[\lambda_ke^{\beta_kt}]^{1(H_t=1,X_t=k)}(1-\lambda_ke^{\beta_kt})^{1(H_t=0,X_t=k)}
\end{aligned}
$$
The joint likelihood of effort and state is

$$
\begin{aligned}
P(\mathbf{X},\mathbf{E}|\mathbf{A}) &= P(X_1)P(E_1|X_1)\prod_{t=2}^{T}P(X_t|X_{t-1},E_{t-1})P(E_t|X_t)\\
P(X_1) &= \prod_{k=1}^{M_x}(\pi^k)^{I(X_1=k)}\\
P(E_t|X_t) &=\prod_{j=1}^J(\gamma_j^k)^{I(A(t)=j,X_t=k,E_t=1)}(1-\gamma_j^k)^{I(A(t)=j,X_t=k,E_t=0)}\\
P(X_t|X_{t-1},E_{t-1})&=[\prod_{j=1}^J[1^{I(x_{t-1}=M_x,x_t=M_x)}][\prod_{k=1}^{M_x-1} 1^{I(A(t)=j,x_{t-1}=k,x_t=k,e_t=0)}(1-\sum_{n=k+1}^{M_x} \ell^{k,n}_j)1^{I(A(t)=j,x_{t-1}=k,x_t=k,e_t=1)}][\prod_{k=1}^{M_x-1}\prod_{n=k+1}^{M_x}(\ell^{k,n}_j)^{I(A(t)=j,X_{t-1}=k,X_t=n,E_t=1)}]
\end{aligned}
$$

#### The Brute Force Algorithm

Given parameters $\Theta$, the joint likelihood $P(\mathbf{Y},  \mathbf{E}, \mathbf{H}, \mathbf{X}|\mathbf{A},\Theta)$ can be calculated. Thus it is trivial to calculate the following quantities:

$$
\begin{aligned}
P(X_t=n,\mathbf{Y},\mathbf{E},\mathbf{H},\mathbf{A},\Theta)&=\sum_{X_1}\dots\sum_{X_t=n}\dots\sum_{X_T} P(\mathbf{X},\mathbf{Y},\mathbf{E},\mathbf{H},\mathbf{A},\Theta)\\
P(X_{t-1}=m,X_t=n,\mathbf{Y},\mathbf{E},\mathbf{H},\mathbf{A},\Theta)&=\sum_{X_1}\dots\sum_{X_{t-1}=m}\sum_{X_t=n}\dots\sum_{X_T} P(\mathbf{X},\mathbf{Y},\mathbf{E},\mathbf{H},\mathbf{A},\Theta)
\end{aligned}
$$
With the joint probability, calculate the conditional probability used in sampling

$$
\begin{aligned}
P(X_T=n|\mathbf{Y},\mathbf{E},\mathbf{H},\mathbf{A},\Theta)&=  \frac{P(X_T=n,\mathbf{Y},\mathbf{E},\mathbf{H},\mathbf{A},\Theta)}{\sum_{k=1}^{M_x}P(X_T=k,\mathbf{Y},\mathbf{E},\mathbf{H},\mathbf{A},\Theta)}\\
P(X_{t-1}=m|,X_t=n,\mathbf{Y},\mathbf{E},\mathbf{H},\mathbf{A},\Theta) &= \frac{P(X_{t-1}=m,X_t=n,\mathbf{Y},\mathbf{E},\mathbf{H},\mathbf{A},\Theta)}{P(X_t=n,\mathbf{Y},\mathbf{E},\mathbf{H},\mathbf{A},\Theta)} \quad (1)
\end{aligned}
$$
The state is sampled by the following steps:

1. Draw the state at the end of the sequence ($T$) from a multinomial distribution with probability mass function $P(X_{T}=k|\mathbf{Y},\mathbf{E},\mathbf{H},\mathbf{A})$
2. Given the state drew at next sequence ($t+1$), draw the current state from from a multinomial distribution with probability mass function $P(X_t=k|,X_t=n,\mathbf{Y},\mathbf{E},\mathbf{H},\mathbf{A})$

#### The Forward Recursion and Backward Sampling Algorithm

In essence, the forward recursion and backward sampling algorithm is identical to the brute force algorithm. However, instead of exhausting all the state combinations and marginalize at each sequence, the FRBS algorithm uses recursive formula and the first order markov chain independence to reduce the computation complexity. 

The key observations is that it is not necessary to condition on all observed variables in equation (1). Because of the first order markov independence, 

$$
X_t\perp\!\!\!\perp \mathbf{X}_{t+2,T}|X_{t+1}
$$
Therefore
$$
X_t\perp\!\!\!\perp \mathbf{Y}_{t+2,T},\mathbf{E}_{t+2,T},\mathbf{H}_{t+2,T}|X_{t+1}
$$

Therefore 
$$
P(X_t|X_{t+1},\mathbf{Y},\mathbf{E},\mathbf{H},\Theta) = P(X_t|X_{t+1},\mathbf{Y}_{1,t+1},\mathbf{E}_{1,t+1},\mathbf{H}_{1,t+1},\Theta)
$$

it is sufficient to sample backward according to 

$$
P(X_t|X_{t+1},\mathbf{Y}_{1,t+1},\mathbf{E}_{1,t+1},\mathbf{H}_{1,t+1},\Theta) = \frac{P(X_t,X_{t+1}|\mathbf{Y}_{1,t+1},\mathbf{E}_{1,t+1},\mathbf{H}_{1,t+1},\Theta)}{\sum_{X_{t+1}}P(X_t,X_{t+1}|\mathbf{Y}_{1,t+1},\mathbf{E}_{1,t+1},\mathbf{H}_{1,t+1},\Theta)} \quad(2)
$$
Therefore the key is to calculate the partial conditional joint state density $P(X_t,X_{t+1}|\mathbf{Y}_{1,t+1},\mathbf{E}_{1,t+1},\mathbf{H}_{1,t+1},\Theta)$. This quantity can be calculated by recursive method. Define the partial conditional marginal state  density $\tilde{\pi}^k_t$ and  the partial conditional joint state density $\tilde{p}^{n,k}_t$.

$$
\begin{aligned}
\tilde{\pi}^k_t & =P(X_t=k|\mathbf{Y}_{1,t},\mathbf{E}_{1,t},\mathbf{A}_{1,t} ,\mathbf{H}_{1,t}, \Theta)\\
\tilde{p}^{n,k}_{t+1}&=P(X_t=k,X_{t+1}=n|\mathbf{Y}_{1,t+1},\mathbf{E}_{1,t+1},\mathbf{A}_{1,t+1} ,\mathbf{H}_{1,t+1}, \Theta)
\end{aligned}
$$
The recursive algorithm is:

1. Given $\tilde{\pi}^k_t$, calculate the partial conditional joint density

$$
\tilde{p}^{n,k}_{t+1} = \tilde{\pi}_t^k P(X_{t+1}=n|X_{t-1}=k,E_{t-1})P(Y_{t+1}|X_{t+1},E_{t+1})P(E_{t+1}|X_{t+1})P(H_{t+1}|X_{t+1},H_t=0)
$$

2. Given $\tilde{p}^{n,k}_{t+1}$, calculate the partial conditional marginal density

$$
\tilde{\pi}_{t+1}^n=\sum_{k=1}^{M_x}\tilde{p}^{n,k}_{t+1}
$$

The sampling algorithm is:

1. Draw the state at the end of the sequence ($T$) from a multinomial distribution with probability mass function $P(X_T=k)=\tilde{\pi}_T^k$

2. Given the state drew at next sequence ($t+1$), draw the current state from from a multinomial distribution with probability mass function $P(X_t=k) = \frac{\tilde{p}^{n,k}_{t+1}}{\sum_{n=1}^{M_x} \tilde{p}^{n,k}_{t+1}}$ given $X_{t+1}=n$




### Parameter Update
The parameters are updated by the Gibbs sampler. Other than the parameters of the hazard model, the likelihood are multinomial, thus has conjugate prior dirichelet distribution. Although the parameters of the hazard model cannot be drew from known distribution, it can still be drew from the marginal conditional distribution by the adaptive rejection sampling.

#### Prior 
The initial state density distribution $\{\pi_1,\dots,\pi_{M_x}\}$, the correct rate of each item conditional on the latent state $\{c_j^{1,k},\dots,c_j^{M_y,k}\}$, the effort rates of each item $\{\gamma_j^1,\dots,\gamma_j^{M_x}\}$ all have non-informative dirichelet distribution $Dir(1,\dots,1)$. In case where the number of state is two, the dirchelet distribution collapses to beta distribution $B(1,1)$.

#### Conjugate Posterior 
The initial state density is drawn from the posterior distribution $Dir(a_{X_1},\dots,a_{X_{M_x}})$ where $a_{X_k} = 1+\sum_{i=1}^N I(X^i_1=k)$.

The Effort rates conditional on the latent state mastery ($X=k$) are drawn from the posterior distribution $Beta(a_{E_0},a_{E_1})$ where $a_{E_e} = 1+\sum_{i=1}^N I(E_t=e, X^i_1=k)$.

The correct rates conditional on the latent state mastery ($X=k$) are drawn from the posterior distribution $Dir(a_{Y_1},\dots,a_{Y_{M_y}})$ where $a_{Y_r} = 1+\sum_{i=1}^N I(Y^i_t=r,X^i_1=k,E_t=1)$.


#### Adaptive Rejection Sampling (ARS)
The discrete time hazard model with time varying covariates has no conjugate prior that produces a posterior distribution easy to draw from. This problem is first solved by Dellaportas and Smith[-@dellaportas1993bayesian] with the adaptive rejection sampling algorithm[@gilks1992adaptive]. As long as the target likelihood function is log-concave, one can draw from the distribution by drawing from the interval of two sandwiching piecewise spline functions. By constructing an upper hall and a lower hull to sandwich the true posterior distribution, the adaptive rejection sampler reduces the computational expanses to draw from a non-standard distribution, compared to the standard rejection method. A brief description of the ARS algorithm is described in appendix (3).


It can be proved (as in Appendix 4) that the full conditional likelihood function for the hazard parameters are indeed log-concave. Therefore, the adaptive rejection sampling algorithm can be applied to update the parameter. However, there are two additional issues. First, the range of $\lambda_k$ and $\beta_k$.is constrained because the hazard rate is strictly less than 1 for sequence max to $T$. Given $T$ and $\lambda_k$, $\beta_k\in(-\infty,\frac{log(\lambda_k)}{T})$; Given $T$, $\lambda_k\in(0,\frac{1}{e^{\beta_kT}})$. The range is then passed into the ARS algorithm to ensure that parameters drawn are always valid. Second, when number of observations grow, the algorithm may experience numerical overflow. To prevent this, scale the log likelihood to be larger than -3000. 

The prior distribution of the parameters are chosen to be uniform distribution to facilitate the posterior draw and justify assigning zero mass to certain interval on the parameter space to enforce the range constraints. Unfortutely, the lower bound only exits for the $\lambda_k$. Set the lower bound of $\beta_k$ to be -1. Start the draw from the $\epsilon$ from the boundary, where $\epsilon=0.01$. If the initial draws produces numerical overflow, symmetrically narrow the bound by a step size of 0.1 until a valid draw occured.  



## Simulation

This section provides a simulation study on the parameter convergence. 

### The data generating process

The true data generating process has $M_x = 3$, $M_y =3$, $J=2$, with both effort choice and stop choice.

The initial state density is:

$$
P(X)= \Bigg\{ \begin{array}{cc}
0.6 & \text{if }X=1 \\
0.3 & \text{if }X=2 \\
0.1 & \text{if }X = 3
\end{array}
$$
The state transtion matrix for item 1 is 

$$
\begin{bmatrix}
0.5 & 0.3 & 0.2\\
0 & 0.4 & 0.6\\
0 & 0 & 1
\end{bmatrix}
$$

The state transtion matrix for item 2 is 
$$
\begin{bmatrix}
0.2 & 0.3 & 0.5\\
0 & 0.7 & 0.3\\
0 & 0 & 1
\end{bmatrix}
$$

The observation matrix for item 1 is
$$
\begin{bmatrix}
0.8 & 0.2 & 0\\
0.2 & 0.6 & 0.2\\
0 & 0.2 & 0.8
\end{bmatrix}
$$

The observation matrix for item 2 is 
$$
\begin{bmatrix}
0.5 & 0.5 & 0\\
0.3 & 0.4 & 0.3\\
0 & 0.1 & 0.9
\end{bmatrix}
$$

The effort matrix for item 1 is
$$
\begin{bmatrix}
0.8 & 0.2\\
0.5 & 0.5\\
0.1 & 0.9
\end{bmatrix}
$$

The effort matrix for item 2 is 
$$
\begin{bmatrix}
0.7 & 0.3\\
0.4 & 0.6\\
0.01 & 0.99
\end{bmatrix}
$$
The baseline hazard rate is 
$$
\lambda= \Bigg\{ \begin{array}{cc}
0.3 & \text{if }X=1 \\
0.2 & \text{if }X=2 \\
0.1 & \text{if }X = 3
\end{array}
$$

The duration dependence is 

$$
\beta= \Bigg\{ \begin{array}{cc}
1.2 & \text{if }X=1 \\
1.1 & \text{if }X=2 \\
1 & \text{if }X = 3
\end{array}
$$

### The data fit

## (APPENDIX) Appendix {-} 

### 1. Proof of Sufficient Statistics

Because IA 1, the total likelihood function is 

$$
L = \prod_{i=1}^NP(\mathbf{Y}=\mathbf{y}^i,\mathbf{A}=\mathbf{a}^i, \mathbf{E}=\mathbf{e}^i,\mathbf{H}=\mathbf{h}^i)
$$

Apply the mapping function, the total likelihood is equivalent to 

$$
\begin{aligned}
L &= \prod_{i=1}^NP(\Omega=G(\mathbf{y}^i,\mathbf{a}^i,\mathbf{e}^i,\mathbf{h}^i))\\
  &= \prod_{\omega=1}^{N_D} P(\Omega=\omega)^{\sum_{i=1}^N I(G(\mathbf{y}^i,\mathbf{a}^i,\mathbf{e}^i,\mathbf{h}^i)=\omega)}\\
\end{aligned}
$$

Since the likelihood function is expressed as a multinomial distribution, it is easy to see that the counts $\{n_1,\dots,n_{N_D}\}$ where $n_{\omega}=\sum_{i=1}^N I(G(\mathbf{y}^i,\mathbf{a}^i,\mathbf{e}^i,\mathbf{h}^i)=\omega)$ are sufficient statistics.

### 2. Proof of Identification of BKT model

First prove the non-degenerate case where where $0<\pi<1$, $0<\ell<1$, and $c^{1,1} \neq c^{1,2}$.

Let $p_{ijk} = P(Y_1=i,Y_2=j,Y_3=k)$, $p_{i,j}=P(Y_1=i,Y_2=j)$. Let $c_1=c^{1,2}$, $c_0=c^{1,1}$


Excluding $p_{0,0,0}$, the rest seven moment conditions are:

$$
\begin{aligned}
p_{111} &=(1-\pi)(1-\ell)c_0^3+(1-\pi)(1-\ell)\ell c_0^2c_1 + (1-\pi)\ell c_0c_1^2+\pi c_1^3 \quad(1)\\
p_{110} &=(1-\pi)(1-\ell)c_0^2(1-c_0)+(1-\pi)(1-\ell)\ell c_0^2(1-c_1) + (1-\pi)\ell c_0c_1(1-c_1)+\pi c_1^2(1-c_1)\quad(2) \\
p_{101} &=(1-\pi)(1-\ell)c_0^2(1-c_0)+(1-\pi)(1-\ell)\ell c_0(1-c_0)c_1 + (1-\pi)\ell c_0(1-c_1)c_1+\pi c_1^2(1-c_1) \quad(3)\\
p_{011} &=(1-\pi)(1-\ell)c_0^2(1-c_0)+(1-\pi)(1-\ell)\ell (1-c_0)c_0c_1 + (1-\pi)\ell (1-c_0)c_1^2+\pi c_1^2(1-c_1) \quad(4)\\
p_{100} &=(1-\pi)(1-\ell)c_0(1-c_0)^2+(1-\pi)(1-\ell)\ell c_0(1-c_0)(1-c_1) + (1-\pi)\ell c_0(1-c_1)^2+\pi c_1(1-c_1)^2 \quad(5)\\
p_{010} &=(1-\pi)(1-\ell)c_0(1-c_0)^2+(1-\pi)(1-\ell)\ell (1-c_0)c_0(1-c_1) + (1-\pi)\ell (1-c_0)(1-c_1)c_1+\pi c_1(1-c_1)^2 \quad(6)\\
p_{001} &=(1-\pi)(1-\ell)c_0(1-c_0)^2+(1-\pi)(1-\ell)\ell (1-c_0)^2c_1 + (1-\pi)\ell (1-c_0)(1-c_1)c_1+\pi c_1(1-c_1)^2 \quad(7)\\
\end{aligned}
$$

Now, generate derivative statistics. $p_{1,1}=p_{1,1,1} +p_{1,1,0}$, $p_{0,1}=p_{0,1,1} +p_{0,1,0}$, $p_{1,0}=p_{1,0,1} +p_{1,0,0}$.
$$
\begin{aligned}
p_{11} &= (1-\pi)(1-\ell)c_0^2+(1-\pi)\ell c_0c_1+\pi c_1^2 \quad(8)\\
p_{01} &= (1-\pi)(1-\ell)(1-c_0)c_0+(1-\pi)\ell (1-c_0)c_1+\pi (1-c_1)c_1 \quad(9) \\
p_{10} &= (1-\pi)(1-\ell)c_0(1-c_0)+(1-\pi)\ell c_0(1-c_1)+\pi c_1(1-c_1)\quad(10)\\
\end{aligned}
$$

$$
\begin{aligned}
p_{01} - p_{10} &= (1-\pi)\ell(c_1-c_0) \quad (11)\\
p_{101}-p_{011} &= (1-\pi)\ell c_1(c_1-c_0)\\
\end{aligned}
$$

If $\pi!=1$, $\ell=0$ and $c_1=c_0$, 
$$
c_1 = \frac{p_{101}-p_{011}}{p_{01} - p_{10}}
$$

$$
\begin{aligned}
p_{110}-p_{101} &= (1-\pi)(1-\ell)\ell c_0(c_1-c_0) \\
p_{001}-p_{010} &= (1-\pi)(1-\ell)\ell (1-c_0)(c_1-c_0)\\
\end{aligned}
$$

If $\pi!=1$, $0<\ell<1$ and $c_1=c_0$,  

$$
c_0=\frac{p_{110}-p_{101}}{p_{110}-p_{101}+p_{001}-p_{010}}
$$
sum over $p_{11}$ and $p_{10}$ and solve for $\pi$ 

$$
\pi = \frac{p_{10}+p_{01}-\frac{p_{110}-p_{101}}{p_{110}-p_{101}+p_{001}-p_{010}}}{\frac{p_{101}-p_{011}}{p_{01} - p_{10}} - \frac{p_{110}-p_{101}}{p_{110}-p_{101}+p_{001}-p_{010}}}
$$

From (11) also solves for 
$$
\ell = \frac{p_{01}-p_{10}}{(1-\pi)(c_1-c_0)} = \frac{p_{01}-p_{10}}{\frac{p_{101}-p_{011}}{p_{01} - p_{10}}-(p_{11}+p_{10})}
$$

Therefore, all parameters are uniquely identified.

Now prove the degenerate case. 
- if $\ell=0$,$0<\pi<1$, the rest of the parameters are identified by three moment conditions $p_{111},p_{110},p_{100}$. 

- If $\pi=1$,$0<\ell<1$, $c_1=\frac{p_{11}}{p_{11}+p_{10}}$, but $\ell$ and $c_0$ are not identified.
- If $\ell=1$,$0<\pi<1$, $c_1=\frac{p_{11}}{p_{11}+p_{10}}$, $\pi$ and $c_0$ are not identified. 
- If $c_1=c_0$, the parameters are not uniquely identified because the states are symmetric.

### 3. A Brief Discription of Adaptive Rejection Sampling Algorithm
(1) Choose a few values $x_j$ from the domain. Construct the upper hull and the lower hull of the target distribution function $f(x)$ by piecewise linear functions of 

$$
\begin{aligned}
u(x) &= f(x_j)+f'(x_j)(x-x_j)\\
l(x) &= \frac{(x_{j+1}-x)f(x_j)+(x-x_j)f(x_{j+1})}{x_{j+1}-x_j}
\end{aligned}
$$

defined over intervals $x\in(z_{j-1},z_j)$ where 

$$
z_j = \frac{f(x_j)-f(x_{j+1})-x_{j+1}f'(x_{j+1})+x_jf'(x_j)}{f'(x_j)-f'(x_{j+1})}
$$

(2) Sample new value of $x^*$ by the probability of $s(x)$ where

$$
s(x) =\frac{exp(u(x))}{\int_{D_x} exp(u(x)) dx} 
$$

(3) Sample $w$ independently from uniform(0,1). Accept the new value$x^*$ if

$$
w \leq e^{l(x^*)-u(x^*)}
$$
Otherwise, accept the new value$x^*$ if 
$$
w \leq e^{f(x^*)-u(x^*)}
$$
Otherwise reject $x^*$ and draw again.

(4) If $x^*$ is accepted, add to the list of $x_j$ for the next draw.

Because the target distribution function is concave, it follows that $f'(x_1)>0$ and $f'(x_J)<0$. The initial value thus cannot be sampled randomly.


### 4. Log-concavity of the full conditional likelihood function of the Hazard model


For $\lambda$

$$
\begin{aligned}
\frac{\partial \ell}{\partial \lambda_k} &= \sum_{i=1}^N \sum_{t=1}^{T_i} I(X_t^i=k)[-\frac{(1-H_{i,t})e^{\beta_kt}}{1-\lambda_k e^{\beta_kt}}+\frac{H_{i,t}}{\lambda_k}]\\
\frac{\partial^2 \ell}{\partial \lambda_k^2} &= \sum_{i=1}^N \sum_{t=1}^{T_i} I(X_t^i=k)[-\frac{(1-H_{i,t})e^{2\beta_kt}}{(1-\lambda_k e^{\beta_kt})^2}-\frac{H_{i,t}}{\lambda_k^2}]
\end{aligned}
$$

Because $H_{i,t}\geq 0$, $1-H_{i,t}\geq 0$, $e^{\beta_k}\geq0$. Therefore, $\frac{\partial^2 \ell}{\partial \lambda_k^2} <0$.

For $\beta_k$
$$
\begin{aligned}
\frac{\partial \ell}{\partial \beta_k} &= \sum_{i=1}^N \sum_{t=1}^{T_i} I(X_t^i=k)[-\frac{(1-H_{i,t})\lambda_k e^{\beta_k}}{1-\lambda_k e^{\beta_k}}+H_{i,t}]t\\
\frac{\partial^2 \ell}{\partial \beta_k^2} &= \sum_{i=1}^N \sum_{t=1}^{T_i}-I(X_t^i=k)[\frac{1}{1-\lambda e^{\beta_kt}}+\frac{e^{\beta_kt}\lambda_k}{(1-\lambda e^{\beta_kt})^2}]e^{\beta_k}t^2(1-H_{i,t})\lambda_k
\end{aligned}
$$
Because $\lambda e^{\beta_kt}<1$ by definition and $\lambda_k\geq 0$, $\frac{1}{1-\lambda e^{\beta_kt}}+\frac{e^{\beta_kt}\lambda_k}{(1-\lambda e^{\beta_kt})^2}>0$. Futhermore, $1-H_{i,t}> 0 \quad \text{for some i}$, $\frac{\partial^2 \ell}{\partial \beta_k^2} <0$.
