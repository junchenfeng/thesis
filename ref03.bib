@article{imbens2009recent,
  title={Recent developments in the econometrics of program evaluation},
  author={Imbens, Guido W and Wooldridge, Jeffrey M},
  journal={Journal of economic literature},
  volume={47},
  number={1},
  pages={5--86},
  year={2009},
  publisher={American Economic Association}
}

@article{lalonde1986evaluating,
  title={Evaluating the econometric evaluations of training programs with experimental data},
  author={LaLonde, Robert J},
  journal={The American economic review},
  pages={604--620},
  year={1986},
  publisher={JSTOR}
}

@article{slavin2002evidence,
  title={Evidence-based education policies: Transforming educational practice and research},
  author={Slavin, Robert E},
  journal={Educational researcher},
  volume={31},
  number={7},
  pages={15--21},
  year={2002},
  publisher={Sage Publications}
}

@article{lewis2015unfavorable,
  title={The Unfavorable Economics of Measuring the Returns to Advertising},
  author={Lewis, Randall A and Rao, Justin M},
  journal={The Quarterly Journal of Economics},
  pages={qjv023},
  year={2015},
  publisher={Oxford University Press}
}

@book{white_bandit_2012,
  title = {Bandit algorithms for website optimization},
  url = {https://books.google.com/books?hl=en\&lr=\&id=ZhM7Whrl5B4C\&oi=fnd\&pg=PR2\&dq=Bandit+Algorithms+for+Website+Optimization\&ots=wh_pPb0OBy\&sig=H31d0AXsdm4XBKdltLYMymrto9A},
  timestamp = {2015-11-12T16:44:42Z},
  urldate = {2015-11-12},
  publisher = {" {O}'{Reilly} {Media}, {Inc}."},
  author = {White, {John}},
  year = {2012},
  file = {Snapshot:C\:\\Users\\junchen\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\hnzl7nq9.default\\zotero\\storage\\N5JKW26A\\books.html:}
}

@article{scott_multi_2015,
  title = {Multi-armed bandit experiments in the online service economy},
  volume = {31},
  issn = {1526-4025},
  doi = {10.1002/asmb.2104},
  abstract = {The modern service economy is substantively different from the agricultural and manufacturing economies that preceded it. In particular, the cost of experimenting is dominated by opportunity cost rather than the cost of obtaining experimental units. The different economics require a new class of experiments, in which stochastic models play an important role. This article briefly summarizes multi-armed bandit experiments, where the experimental design is modified as the experiment progresses to reduce the cost of experimenting. Special attention is paid to Thompson sampling, which is a simple and effective way to run a multi-armed bandit experiment. Copyright {\textcopyright} 2015 John Wiley \& Sons, Ltd.},
  language = {en},
  timestamp = {2015-11-12T16:45:36Z},
  number = {1},
  urldate = {2015-11-12},
  journal = {Applied {Stochastic} {Models} in {Business} and {Industry}},
  author = {Scott, {Steven} {L}.},
  month = jan,
  year = {2015},
  keywords = {Bayesian,reinforcement learning,sequential experiment,Thompson sampling},
  pages = {37--45},
  file = {Snapshot:C\:\\Users\\junchen\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\hnzl7nq9.default\\zotero\\storage\\5H6PNKGC\\abstract.html:;Full Text PDF:C\:\\Users\\junchen\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\hnzl7nq9.default\\zotero\\storage\\5PU2GRNM\\Scott - 2015 - Multi-armed bandit experiments in the online servi.pdf:application/pdf;multi-armed bandit experiments in online service economy.pdf:C\:\\Users\\junchen\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\hnzl7nq9.default\\zotero\\storage\\QN8UX5KG\\multi-armed bandit experiments in online service economy.pdf:application/pdf}
}

@article{even-dar_action_2006,
  title = {Action elimination and stopping conditions for the multi-armed bandit and reinforcement learning problems},
  volume = {7},
  url = {http://dl.acm.org/citation.cfm?id=1248586},
  timestamp = {2015-11-12T16:54:38Z},
  urldate = {2015-11-12},
  journal = {The {Journal} of {Machine} {Learning} {Research}},
  author = {Even-{Dar}, {Eyal} and {Mannor}, {Shie} and {Mansour}, {Yishay}},
  year = {2006},
  pages = {1079--1105},
  file = {action elimination and stopping condition for the multi-armed bandit and reinforcement learning problem.pdf:C\:\\Users\\junchen\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\hnzl7nq9.default\\zotero\\storage\\5H89MEMA\\action elimination and stopping condition for the multi-armed bandit and reinforcement learning problem.pdf:application/pdf;[PDF] from wustl.edu:C\:\\Users\\junchen\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\hnzl7nq9.default\\zotero\\storage\\7CJPKUSG\\Even-Dar 等. - 2006 - Action elimination and stopping conditions for the.pdf:application/pdf;Snapshot:C\:\\Users\\junchen\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\hnzl7nq9.default\\zotero\\storage\\K3DGBGBQ\\citation.html:}
}

@article{kaufmann_thompson_2012,
  title = {Thompson {Sampling}: {An} {Asymptotically} {Optimal} {Finite} {Time} {Analysis}},
  shorttitle = {Thompson {Sampling}},
  url = {http://arxiv.org/abs/1205.4217},
  abstract = {The question of the optimality of Thompson Sampling for solving the stochastic multi-armed bandit problem had been open since 1933. In this paper we answer it positively for the case of Bernoulli rewards by providing the first finite-time analysis that matches the asymptotic rate given in the Lai and Robbins lower bound for the cumulative regret. The proof is accompanied by a numerical comparison with other optimal policies, experiments that have been lacking in the literature until now for the Bernoulli case.},
  timestamp = {2015-10-26T01:37:48Z},
  urldate = {2015-10-26},
  journal = {{arXiv}:1205.4217 {[}cs, stat]},
  author = {Kaufmann, {Emilie} and {Korda}, {Nathaniel} and {Munos}, {R}{\'e}mi},
  month = may,
  year = {2012},
  keywords = {Computer Science - Learning,Statistics - Machine Learning},
  annote = {Comment: 15 pages, 2 figures, submitted to ALT (Algorithmic Learning Theory)},
  file = {arXiv.org Snapshot:C\:\\Users\\junchen\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\hnzl7nq9.default\\zotero\\storage\\E8S3JNNQ\\1205.html:;arXiv\:1205.4217 PDF:C\:\\Users\\junchen\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\hnzl7nq9.default\\zotero\\storage\\NG8XMKVB\\Kaufmann 等. - 2012 - Thompson Sampling An Asymptotically Optimal Finit.pdf:application/pdf},
  arxiv = {1205.4217}
}

@article{scott_modern_2010,
  title = {{A} {Modern} {Bayesian} {Look} at the {Multi}-armed {Bandit}},
  volume = {26},
  issn = {1524-1904},
  doi = {10.1002/asmb.874},
  abstract = {A multi-armed bandit is an experiment with the goal of accumulating rewards from a payoff distribution with unknown parameters that are to be learned sequentially. This article describes a heuristic for managing multi-armed bandits called randomized probability matching, which randomly allocates observations to arms according the Bayesian posterior probability that each arm is optimal. Advances in Bayesian computation have made randomized probability matching easy to apply to virtually any payoff distribution. This flexibility frees the experimenter to work with payoff distributions that correspond to certain classical experimental designs that have the potential to outperform methods that are `optimal' in simpler contexts. I summarize the relationships between randomized probability matching and several related heuristics that have been used in the reinforcement learning literature. Copyright {\textcopyright} 2010 John Wiley \& Sons, Ltd.},
  timestamp = {2015-10-26T01:40:37Z},
  number = {6},
  urldate = {2015-10-26},
  journal = {Appl. {Stoch}. {Model}. {Bus}. {Ind}.},
  author = {Scott, {Steven} {L}.},
  month = nov,
  year = {2010},
  keywords = {Bayesian adaptive design,exploration vs exploitation,probability matching,sequential design},
  pages = {639--658}
}

@inproceedings{mandel_queue_2015,
  title = {The {Queue} {Method}: {Handling} {Delay}, {Heuristics}, {Prior} {Data}, and {Evaluation} in {Bandits}},
  shorttitle = {The {Queue} {Method}},
  url = {http://grail.cs.washington.edu/projects/bandit/banditpaper.pdf},
  timestamp = {2015-10-26T01:46:40Z},
  urldate = {2015-10-26},
  booktitle = {Twenty-{Ninth} {AAAI} {Conference} on {Artificial} {Intelligence}},
  author = {Mandel, {Travis} and {Liu}, {Yun}-{En} and {Brunskill}, {Emma} and {Popovic}, {Zoran}},
  year = {2015},
  file = {[PDF] from washington.edu:C\:\\Users\\junchen\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\hnzl7nq9.default\\zotero\\storage\\G4M479JW\\Mandel 等. - 2015 - The Queue Method Handling Delay, Heuristics, Prio.pdf:application/pdf}
}

@article{williams_methodology_2015,
  title = {{A} {Methodology} for {Discovering} how to {Adaptively} {Personalize} to {Users} using {Experimental} {Comparisons}},
  url = {http://arxiv.org/abs/1509.04360},
  abstract = {We explain and provide examples of a formalism that supports the methodology of discovering how to adapt and personalize technology by combining randomized experiments with variables associated with user models. We characterize a formal relationship between the use of technology to conduct A/B experiments and use of technology for adaptive personalization. The MOOClet Formalism {[}11] captures the equivalence between experimentation and personalization in its conceptualization of modular components of a technology. This motivates a unified software design pattern that enables technology components that can be compared in an experiment to also be adapted based on contextual data, or personalized based on user characteristics. With the aid of a concrete use case, we illustrate the potential of the MOOClet formalism for a methodology that uses randomized experiments of alternative micro-designs to discover how to adapt technology based on user characteristics, and then dynamically implements these personalized improvements in real time.},
  timestamp = {2015-10-26T01:50:54Z},
  urldate = {2015-10-26},
  journal = {{arXiv}:1509.04360 {[}cs]},
  author = {Williams, {Joseph} {Jay} and {Heffernan}, {Neil}},
  month = sep,
  year = {2015},
  keywords = {Computer Science - Human-Computer Interaction},
  file = {arXiv\:1509.04360 PDF:C\:\\Users\\junchen\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\hnzl7nq9.default\\zotero\\storage\\2SDRBGP7\\Williams 和 Heffernan - 2015 - A Methodology for Discovering how to Adaptively Pe.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\junchen\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\hnzl7nq9.default\\zotero\\storage\\BWJATUM6\\1509.html:},
  arxiv = {1509.04360}
}

@misc{liu_trading_2014,
  title = {Trading {Off} {Scientific} {Knowledge} and {User} {Learning} with {Multi}-{Armed} {Bandits}},
  timestamp = {2015-10-26T01:53:48Z},
  author = {Liu, {Yun}-{En} and {Mandel}, {Travis} and {Brunskill}, {Emma} and {Popovi}{\'c}, {Zoran}},
  year = {2014},
  file = {Trading Off Scientific Knowledge and User Learning with Multi-Armed Bandits | Computer Science & Engineering:C\:\\Users\\junchen\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\hnzl7nq9.default\\zotero\\storage\\9I9Q2UUG\\10428.html:}
}

@inproceedings{liu_automatic_2014,
  address = {New {York}, {NY}, {USA}},
  series = {{CHI} '14},
  title = {Towards {Automatic} {Experimentation} of {Educational} {Knowledge}},
  isbn = {978-1-4503-2473-1},
  doi = {10.1145/2556288.2557392},
  abstract = {We present a general automatic experimentation and hypothesis generation framework that utilizes a large set of users to explore the effects of different parts of an intervention parameter space on any objective function. We also incorporate importance sampling, allowing us to run these automatic experiments even if we cannot give out the exact intervention distributions that we want. To show the utility of this framework, we present an implementation in the domain of fractions and numberlines, using an online educational game as the source of players. Our system is able to automatically explore the parameter space and generate hypotheses about what types of numberlines lead to maximal short-term transfer; testing on a separate dataset shows the most promising hypotheses are valid. We briefly discuss our results in the context of the wider educational literature, showing that one of our results is not explained by current research on multiple fraction representations, thus proving our ability to generate potentially interesting hypotheses to test.},
  timestamp = {2015-10-26T01:57:28Z},
  urldate = {2015-10-26},
  booktitle = {Proceedings of the {32Nd} {Annual} {ACM} {Conference} on {Human} {Factors} in {Computing} {Systems}},
  publisher = {{ACM}},
  author = {Liu, {Yun}-{En} and {Mandel}, {Travis} and {Brunskill}, {Emma} and {Popovi}{\'c}, {Zoran}},
  year = {2014},
  keywords = {datamining,education,games},
  pages = {3349--3358},
  file = {ACM Full Text PDF:C\:\\Users\\junchen\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\hnzl7nq9.default\\zotero\\storage\\2JKUBNCH\\Liu 等. - 2014 - Towards Automatic Experimentation of Educational K.pdf:application/pdf}
}

@article{clement_multi_2013,
  title = {Multi-{Armed} {Bandits} for {Intelligent} {Tutoring} {Systems}},
  url = {http://arxiv.org/abs/1310.3174},
  abstract = {We present an approach to Intelligent Tutoring Systems which adaptively personalizes sequences of learning activities to maximize skills acquired by students, taking into account the limited time and motivational resources. At a given point in time, the system proposes to the students the activity which makes them progress faster. We introduce two algorithms that rely on the empirical estimation of the learning progress, RiARiT that uses information about the difficulty of each exercise and ZPDES that uses much less knowledge about the problem. The system is based on the combination of three approaches. First, it leverages recent models of intrinsically motivated learning by transposing them to active teaching, relying on empirical estimation of learning progress provided by specific activities to particular students. Second, it uses state-of-the-art Multi-Arm Bandit (MAB) techniques to efficiently manage the exploration/exploitation challenge of this optimization process. Third, it leverages expert knowledge to constrain and bootstrap initial exploration of the MAB, while requiring only coarse guidance information of the expert and allowing the system to deal with didactic gaps in its knowledge. The system is evaluated in a scenario where 7-8 year old schoolchildren learn how to decompose numbers while manipulating money. Systematic experiments are presented with simulated students, followed by results of a user study across a population of 400 school children.},
  timestamp = {2015-10-26T02:00:47Z},
  urldate = {2015-10-26},
  journal = {{arXiv}:1310.3174 {[}cs]},
  author = {Clement, {Benjamin} and {Roy}, {Didier} and {Oudeyer}, {Pierre}-{Yves} and {Lopes}, {Manuel}},
  month = oct,
  year = {2013},
  keywords = {Computer Science - Artificial Intelligence},
  file = {arXiv\:1310.3174 PDF:C\:\\Users\\junchen\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\hnzl7nq9.default\\zotero\\storage\\5HZRKAPW\\Clement 等. - 2013 - Multi-Armed Bandits for Intelligent Tutoring Syste.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\junchen\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\hnzl7nq9.default\\zotero\\storage\\FTUEDGCP\\1310.html:},
  arxiv = {1310.3174}
}

@article{einav_economics_2014,
  title = {Economics in the age of big data},
  volume = {346},
  issn = {0036-8075, 1095-9203},
  doi = {10.1126/science.1243089},
  abstract = {The quality and quantity of data on economic activity are expanding rapidly. Empirical research increasingly relies on newly available large-scale administrative data or private sector data that often is obtained through collaboration with private firms. Here we highlight some challenges in accessing and using these new data. We also discuss how new data sets may change the statistical methods used by economists and the types of questions posed in empirical research.
Background Economic science has evolved over several decades toward greater emphasis on empirical work. The data revolution of the past decade is likely to have a further and profound effect on economic research. Increasingly, economists make use of newly available large-scale administrative data or private sector data that often are obtained through collaborations with private firms, giving rise to new opportunities and challenges.
The rising use of non{\textendash}publicly available data in economic research. Here we show the percentage of papers published in the American Economic Review (AER) that obtained an exemption from the AER's data availability policy, as a share of all papers published by the AER that relied on any form of data (excluding simulations and laboratory experiments). Notes and comments, as well as AER Papers and Proceedings issues, are not included in the analysis. We obtained a record of exemptions directly from the AER administrative staff and coded each exemption manually to reflect public sector versus private data. Our check of nonexempt papers suggests that the AER records may possibly understate the percentage of papers that actually obtained exemptions. The asterisk indicates that data run from when the AER started collecting these data (December 2005 issue) to the September 2014 issue. To make full use of the data, we define year 2006 to cover October 2005 through September 2006, year 2007 to cover October 2006 through September 2007, and so on.
Advances These new data are affecting economic research along several dimensions. Many fields have shifted from a reliance on relatively small-sample government surveys to administrative data with universal or near-universal population coverage. This shift is transformative, as it allows researchers to rigorously examine variation in wages, health, productivity, education, and other measures across different subpopulations; construct consistent long-run statistical indices; generate new quasi-experimental research designs; and track diverse outcomes from natural and controlled experiments. Perhaps even more notable is the expansion of private sector data on economic activity. These data, sometimes available from public sources but other times obtained through data-sharing agreements with private firms, can help to create more granular and real-time measurement of aggregate economic statistics. The data also offer researchers a look inside the {\textquotedblleft}black box{\textquotedblright} of firms and markets by providing meaningful statistics on economic behavior such as search and information gathering, communication, decision-making, and microlevel transactions. Collaborations with data-oriented firms also create new opportunities to conduct and evaluate randomized experiments. Economic theory plays an important role in the analysis of large data sets with complex structure. It can be difficult to organize and study this type of data (or even to decide which variables to construct) without a simplifying conceptual framework, which is where economic models become useful. Better data also allow for sharper tests of existing models and tests of theories that had previously been difficult to assess.
Outlook The advent of big data is already allowing for better measurement of economic effects and outcomes and is enabling novel research designs across a range of topics. Over time, these data are likely to affect the types of questions economists pose, by allowing for more focus on population variation and the analysis of a broader range of economic activities and interactions. We also expect economists to increasingly adopt the large-data statistical methods that have been developed in neighboring fields and that often may complement traditional econometric techniques. These data opportunities also raise some important challenges. Perhaps the primary one is developing methods for researchers to access and explore data in ways that respect privacy and confidentiality concerns. This is a major issue in working with both government administrative data and private sector firms. Other challenges include developing the appropriate data management and programming capabilities, as well as designing creative and scalable approaches to summarize, describe, and analyze large-scale and relatively unstructured data sets. These challenges notwithstanding, the next few decades are likely to be a very exciting time for economic research.},
  language = {en},
  timestamp = {2015-11-12T17:08:35Z},
  number = {6210},
  urldate = {2015-11-12},
  journal = {Science},
  author = {Einav, {Liran} and {Levin}, {Jonathan}},
  month = jul,
  year = {2014},
  pages = {1243089},
  file = {Snapshot:C\:\\Users\\junchen\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\hnzl7nq9.default\\zotero\\storage\\BPBIS6SX\\1243089.html:;Full Text PDF:C\:\\Users\\junchen\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\hnzl7nq9.default\\zotero\\storage\\IDG9PKQ6\\Einav 和 Levin - 2014 - Economics in the age of big data.pdf:application/pdf},
  pmid = {25378629}
}

@article{gittins_bandit_1979,
  title = {Bandit processes and dynamic allocation indices},
  url = {http://www.jstor.org/stable/2985029},
  timestamp = {2015-11-12T17:32:14Z},
  urldate = {2015-11-12},
  journal = {Journal of the {Royal} {Statistical} {Society}. {Series} {B} ({Methodological})},
  author = {Gittins, {John} {C}.},
  year = {1979},
  pages = {148--177}
}

@article{yu_when_2013,
  title = {When decision heuristics and science collide},
  volume = {21},
  issn = {1069-9384, 1531-5320},
  doi = {10.3758/s13423-013-0495-z},
  abstract = {The ongoing discussion among scientists about null-hypothesis significance testing and Bayesian data analysis has led to speculation about the practices and consequences of {\textquotedblleft}researcher degrees of freedom.{\textquotedblright} This article advances this debate by asking the broader questions that we, as scientists, should be asking: How do scientists make decisions in the course of doing research, and what is the impact of these decisions on scientific conclusions? We asked practicing scientists to collect data in a simulated research environment, and our findings show that some scientists use data collection heuristics that deviate from prescribed methodology. Monte Carlo simulations show that data collection heuristics based on p values lead to biases in estimated effect sizes and Bayes factors and to increases in both false-positive and false-negative rates, depending on the specific heuristic. We also show that using Bayesian data collection methods does not eliminate these biases. Thus, our study highlights the little appreciated fact that the process of doing science is a behavioral endeavor that can bias statistical description and inference in a manner that transcends adherence to any particular statistical framework.},
  language = {en},
  timestamp = {2015-11-17T18:20:38Z},
  number = {2},
  urldate = {2015-11-17},
  journal = {Psychonomic {Bulletin} \& {Review}},
  author = {Yu, {Erica} {C}. and {Sprenger}, {Amber} {M}. and {Thomas}, {Rick} {P}. and {Dougherty}, {Michael} {R}.},
  month = sep,
  year = {2013},
  keywords = {Bayes factor,Cognitive Psychology,Decision making,Heuristics,Law of small numbers,Sampling policies},
  pages = {268--282},
  file = {Full Text PDF:C\:\\Users\\junchen\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\hnzl7nq9.default\\zotero\\storage\\8CEPAJIC\\Yu 等. - 2013 - When decision heuristics and science collide.pdf:application/pdf;Snapshot:C\:\\Users\\junchen\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\hnzl7nq9.default\\zotero\\storage\\R44SGWTB\\10.html:}
}

@article{lai_asymptotically_1985,
  title = {Asymptotically efficient adaptive allocation rules},
  volume = {6},
  issn = {0196-8858},
  doi = {10.1016/0196-8858(85)90002-8},
  timestamp = {2015-11-12T17:35:26Z},
  number = {1},
  urldate = {2015-11-12},
  journal = {Advances in {Applied} {Mathematics}},
  author = {Lai, {T}. {L} and {Robbins}, {Herbert}},
  month = mar,
  year = {1985},
  pages = {4--22},
  file = {ScienceDirect Snapshot:C\:\\Users\\junchen\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\hnzl7nq9.default\\zotero\\storage\\KK3AIUXI\\0196885885900028.html:}
}

@article{lai_adaptive_1987,
  title = {Adaptive {Treatment} {Allocation} and the {Multi}-{Armed} {Bandit} {Problem}},
  volume = {15},
  issn = {0090-5364},
  url = {http://www.jstor.org/stable/2241818},
  abstract = {A class of simple adaptive allocation rules is proposed for the problem (often called the "multi-armed bandit problem") of sampling x1, \ensuremath{\cdots} xN sequentially from k populations with densities belonging to an exponential family, in order to maximize the expected value of the sum SN = x1 + \ensuremath{\cdots} + xN. These allocation rules are based on certain upper confidence bounds, which are developed from boundary crossing theory, for the k population parameters. The rules are shown to be asymptotically optimal as N \ensuremath{\rightarrow} \ensuremath{\infty} from both Bayesian and frequentist points of view. Monte Carlo studies show that they also perform very well for moderate values of the horizon N.},
  timestamp = {2015-11-12T17:36:26Z},
  number = {3},
  urldate = {2015-11-12},
  journal = {The {Annals} of {Statistics}},
  author = {Lai, {Tze} {Leung}},
  year = {1987},
  pages = {1091--1114},
  file = {JSTOR Full Text PDF:C\:\\Users\\junchen\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\hnzl7nq9.default\\zotero\\storage\\I9PGZWGB\\Lai - 1987 - Adaptive Treatment Allocation and the Multi-Armed .pdf:application/pdf}
}

@article{auer_finite_2002,
  title = {Finite-time analysis of the multiarmed bandit problem},
  volume = {47},
  url = {http://link.springer.com/article/10.1023/a:1013689704352},
  timestamp = {2015-11-12T17:39:38Z},
  number = {2-3},
  urldate = {2015-11-12},
  journal = {Machine learning},
  author = {Auer, {Peter} and {Cesa}-{Bianchi}, {Nicolo} and {Fischer}, {Paul}},
  year = {2002},
  pages = {235--256},
  file = {Snapshot:C\:\\Users\\junchen\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\hnzl7nq9.default\\zotero\\storage\\FNZHGVK9\\a1013689704352.html:}
}

@article{sanborn_frequentist_2014,
  title = {The frequentist implications of optional stopping on {Bayesian} hypothesis tests},
  volume = {21},
  url = {http://link.springer.com/article/10.3758/s13423-013-0518-9},
  timestamp = {2015-11-17T18:23:06Z},
  number = {2},
  urldate = {2015-11-17},
  journal = {Psychonomic bulletin \& review},
  author = {Sanborn, {Adam} {N}. and {Hills}, {Thomas} {T}.},
  year = {2014},
  pages = {283--300},
  file = {Snapshot:C\:\\Users\\junchen\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\hnzl7nq9.default\\zotero\\storage\\XA78CSAF\\s13423-013-0518-9.html:}
}

@article{hoenig_abuse_2001,
  title = {The abuse of power},
  volume = {55},
  url = {http://amstat.tandfonline.com/doi/abs/10.1198/000313001300339897},
  timestamp = {2015-11-18T02:22:54Z},
  number = {1},
  urldate = {2015-11-18},
  journal = {The {American} {Statistician}},
  author = {Hoenig, {John} {M}. and {Heisey}, {Dennis} {M}.},
  year = {2001},
  file = {Snapshot:C\:\\Users\\junchen\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\hnzl7nq9.default\\zotero\\storage\\G9ETUNBF\\000313001300339897.html:}
}

@book{mukhopadhyay_sequential_2009,
  address = {Boca {Raton}},
  title = {Sequential methods and their applications},
  isbn = {9781584881025 (hardcover: acid-free paper)},
  lccn = {QA279.7 .M85 2009 (Crerar Library)},
  shorttitle = {Sequential methods and their applications},
  language = {English},
  timestamp = {2015-11-18T19:53:31Z},
  publisher = {{CRC} {Press}},
  author = {Mukhopadhyay, {Nitis} and de. {Silva}, {Basil} {M}.},
  year = {2009},
  keywords = {Sequential analysis}
}

@inproceedings{chapelle_empirical_2011,
  title = {An empirical evaluation of thompson sampling},
  url = {http://papers.nips.cc/paper/4321-an-empirical-evaluation-of-thompson-sampling},
  timestamp = {2015-11-18T21:41:28Z},
  urldate = {2015-11-18},
  booktitle = {Advances in neural information processing systems},
  author = {Chapelle, {Olivier} and {Li}, {Lihong}},
  year = {2011},
  pages = {2249--2257},
  file = {[HTML] from nips.cc:C\:\\Users\\junchen\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\hnzl7nq9.default\\zotero\\storage\\P9GD634T\\4321-an-empirical-evaluation-of-thompson-sampling.html:}
}

@article{kulldorff_maximized_2011,
  title = {{A} {Maximized} {Sequential} {Probability} {Ratio} {Test} for {Drug} and {Vaccine} {Safety} {Surveillance}},
  volume = {30},
  issn = {0747-4946},
  doi = {10.1080/07474946.2011.539924},
  abstract = {Because of rare but serious adverse events, pharmaceutical drugs and vaccines are sometimes withdrawn from the market, either by a government agency such as the Food and Drug Administration (FDA) in the United States or by the manufacturing pharmaceutical company. In other cases, a drug may be generally safe but increase the risk for serious adverse events for certain subpopulations such as pregnant women or people with heart problems. Due to limited sample size and selected study populations, rare adverse events are often impossible to detect during phase 3 trials conducted before the drug is approved for general use. It is then important to conduct post-approval drug safety surveillance, using, for example, health insurance claims data. In such surveillance, the goal should be to detect serious adverse events as early as possible without too many false alarms, and it is then natural to use a continuous or near-continuous sequential test procedure that reevaluates the data on a daily or weekly basis. In this article, we first show that Wald's classical sequential probability ratio test (SPRT) for continuous surveillance is very sensitive to the choice of relative risk required in the specification of the alternative hypothesis, making it difficult to use for drug and vaccine safety surveillance. We instead propose the use of a maximized sequential probability ratio test (MaxSPRT) based on a composite alternative hypothesis, which works well across a range of relative risks. We illustrate the use of this method on vaccine safety surveillance and compare it with the classical SPRT. A table of critical values for the MaxSPRT is provided, covering most parameter choices relevant for vaccine and drug safety surveillance. The critical values are based on exact numerical calculations. We also calculate the statistical power, the expected time until the null hypothesis is rejected, and the average length of surveillance.},
  timestamp = {2015-11-19T20:24:27Z},
  number = {1},
  urldate = {2015-11-19},
  journal = {Sequential {Analysis}},
  author = {Kulldorff, {Martin} and {Davis}, {Robert} {L}. and {Kolczak}{\textdagger}, {Margarette} and {Lewis}, {Edwin} and {Lieu}, {Tracy} and {Platt}, {Richard}},
  month = jan,
  year = {2011},
  pages = {58--78},
  file = {Snapshot:C\:\\Users\\junchen\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\hnzl7nq9.default\\zotero\\storage\\JAAM7B3C\\07474946.2011.html:;Full Text PDF:C\:\\Users\\junchen\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\hnzl7nq9.default\\zotero\\storage\\RV6CDH7G\\Kulldorff 等. - 2011 - A Maximized Sequential Probability Ratio Test for .pdf:application/pdf}
}

@book{siegmund_sequential_2013,
  title = {Sequential analysis: tests and confidence intervals},
  shorttitle = {Sequential analysis},
  url = {https://books.google.com/books?hl=zh-CN\&lr=\&id=bGTTBwAAQBAJ\&oi=fnd\&pg=PA1\&dq=sequential+analysis+david\&ots=GWTZZNdV5O\&sig=7tuUhMaWgmWEXIXjuKzz48G6e_w},
  timestamp = {2015-12-01T00:43:46Z},
  urldate = {2015-12-01},
  publisher = {{Springer Science \& Business Media}},
  author = {{Siegmund}, David},
  year = {2013},
  file = {Snapshot:C\:\\Users\\junchen\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\hnzl7nq9.default\\zotero\\storage\\H49UKEW7\\books.html:}
}
