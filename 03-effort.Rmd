# Selection Bias of the Effort Decision in the Pedagogical Efficacy Estimation{#efficacy}

```{r, echo=FALSE,message=FALSE,warning=FALSE}
library(dplyr)
library(tidyr)
library(ggplot2)
library(stargazer)
library(gridExtra)
rm(list=ls())

proj_dir = getwd()
input_file_path = paste0(proj_dir,'/_data/03/paper_data.RData')
load(input_file_path)
options(digits=2)

```

## Experimental Evaluation of Pedagogical Efficacy


### The general setup
The second application of the general learning model is motivated by the estimation of pedagogical efficacy in an experiment. The general design of a randomized control trial consists of three components:

(1) The pre-test 

(2) The pedagogical interventions 

(3) The post-test 

The pedagogical efficacy of the interventions is then estimated by a difference in difference framework. Without the loss of generality, assume there are two groups, the treatment ($D=1$) and the control($D=0$). Let the pre-test result be $Y_0$, the post-test result be $Y_1$.The DID estimator is obtained as $\hat{\gamma}$ from  the following equation

$$
Y_{i,T_i} = \beta_d D_i + \beta_t T_i + \gamma D_i\times T_i + \epsilon_{i,T_i}
$$

$\hat{\gamma}$ is in general not a consistent estimator of the pedagogical efficacy, but a consistent estimator of a monotone function of the pedagogical efficacy. Because the response is unlikely to be generated by a uniform random variable, the linear specification of the function form is likely to be wrong. The problem can be mitigated  by adding a fix effect for the pre-test and post-test item. Again, $A(t)$ is the assignment function that maps the item to the experiment sequence. If The pre-test and the post-test uses a fixed item, the item fixed effect is not identified and merges into the time trend.

$$
Y_{i,T_i} = \beta_d D_i + \beta_t T_i + \gamma D_i\times T_i + \eta_{A{T_i}} + \epsilon_{i,T_i}
$$

### Selection bias of the effort choice
In low stake learning environment, the learner can slack during the practice, "without thinking fastidiously". If the pedagogical intervention leads to a different choice of effort level, it is effectively a selection bias. 
 
Through out the chapter, assumes there is no exit choice $H_t=0 \quad \forall t$. In addition, for the sake of simplicity, assume that the pre-test and the post-test item has identical slip rate ($s_j=s$) and guess rate ($g_j=g$). In addition, assumes no learning in the pre-test and post-test and the effort choice is only made on the training question. Under the framework of the general learning model with no effort choice, the DID estimator consistently identifies the quantity of interest, up to a scale.

$$
E(\hat{\gamma}) = (1-\pi)(g-s) (\ell_{D=1}-\ell_{D=0}) 
$$

let $E_D$ be the effort level chosen by group $D$, the bias of the DID estimator is 

$$
\begin{aligned}
Bias(\hat{\gamma}) &= E(\epsilon|E_{D=1}=1)-E(\epsilon|E_{D=0}=1)\\
&=(1-\pi)(s+g-1)(\ell_{D=1}(1-P(E_{D=1}))-\ell_0(1-P(E_{D=0})))
\end{aligned}
$$

Under the assumption that $1>s+g$, the bias is not signed in general. If the probability of making an effort is equal among two groups$P(E_{D=1})=P(E_{D=0})$, the presence of effort shrinks the estimated effect toward 0: If there is a positive effect, the bias is downward; If there is a negative effect, the bias is upward. However, if $\ell$ and $P(E)$ are positively correlated, then $1-P(E_1) < 1-P(E_0)$. Then if the elasticity of the effort over learning gain has to be elastic to produce a mean reverting bias.

**TODO: add a general proof of bias!**

The reader may argue the bias does not matter because engaging the learner is a part of the pedagogical efficacy, defined more broadly. If the alternative pedagogical efficacy is only used in the same learning environment, such argument has merit. However, if the goal is to export the estimated pedagogical efficacy to other learning environments, the estimated efficacy loses external validity because the effort choice may vary along with the environment.


### Bias Correction

Suppose the effort level is observed, it is still difficult to correct for it in the DID estimator, even under the simplest case where the learner only makes effort choice on the training question. Without additional exclusion restriction, the average treatment effect is not identified.The general learning model correct the bias by the power of the strong model structure. Under identification assumption 1-7, all parameters are uniquely identified and the bias can be estimated precisely.

Unfortunately, the effort level is not directly observed, although it may be inferred from auxiliary data. There is a growing literature on how to identify the affective state of the leaner, but it remains an open question. 


## The Dataset

### The Learning Environment

The experiment is carried out in a paid self-learning product offered by a Chinese online learning service provider. The product is used after school, rather than in the classroom.

The product is framed as a role-playing game where the learner clears a level to claim the reward. Level clearance is defined as accumulating 12 correct answers. The screen shots of the initiation, practice and the completion of the level are shown from figure 3.1 to 3.3.

<center>![Figure 4.1: Level Initiation](fig/initial.png)</center>

<center>![Figure 4.2: Practice Interface](fig/practice.png)</center>

<center>![Figure 4.3: Level Completion](fig/completion.png)</center>

The monetary value of the reward for a correct response is very low. The virtual currency (Xuedou) can exchange for in-game gears or real world gifts. During the experiment, the reward for each correct response is about  a tenth of a penny in RMB (or $0.00014). Although the incentive is tiny, the learners nevertheless game the system to efficiently mine the virtual currency. To "encode success into exercises"[@lemov2012practice], the system lowers the cost of errors almost to zero so as to encourage the learners to practice until correct.There is no punishment for an incorrect answer and the correct answer is shown to them before they go to the next question. If they make a mistake, the learner can practice a similar item to earn an additional but smaller reward. Because the reward is independent of the item difficulty, some students developed a strategy to skip difficult items in hope to get an easier one to score a correct response on the first attempt. All these system gaming behavior results in significant measurement error in the logged response. The overall frequency of observing a blank answer for the math practices is about 20%.

Another detail worth mentioning is the interaction when there are multiple sub-questions. The learner does not get feedback on any subquestion but the overall result when they submit all answers. The submit is irreversible. Once the learner moves to the next sub-question, they cannot go back to the last.

### The Design and the Implementation of The Experiment 

The experiment is administrated from June 9th, 2016 to June 10th 2016 to third-grade students whose parents paid for the learning product. By then, all learners should have been taught the required knowledge point in the school. Users were not aware that they were participating in an experiment.


The learning task trains the knowledge point of the circumference and area formula of rectangles. 

The pre-test item (Figure 4.4) asks the learner to calculate the circumference and area of two identical rectangles joined by length, given the length and width of the small rectangle.

<center>![Figure 4.4: The Pre-test Item](fig/f1.png)</center>

The training item is a modified version of the original question(Figure 4.5). The question is identical to the original one except for the value of the length and width. It also preserves the feature that the joined width is the new length.

<center>![Figure 4.5: The Training Exercise](fig/f2.png)</center>

The scaffolding guides the learner to find the width and length of the new shape and then apply the formula. The scaffolding is drawn from the teaching experiment of in-house tutor experts. To wit:

(1) What is the length and width of the new rectangle

(2) What is the circumference of the new rectangle

(3) What is the area of the new rectangle

The post-test item skill (Figure 4.6) asks the learner to calculate the same quantities for two rectangles joined by width. A highly similar yet not identical item enhances the measurement validity while prevents student memorizing the answer.

<center>![Figure 4.6: The Post-test Item](fig/f3.png)</center>


In the 12 item recommendation package, the experiment package occupies the 5th to 7th position for all qualified users in the order of the pre-test, training item, and the post-test. Other items are recommended base on their previous learning record. If the learner does not exit during the level, they finished the experiment in one setting. The control group receives the training item without scaffolding. The first treatment group receives the item with vocabulary description of the scaffolding that the learner solves step by step as sub-questions. The second treatment group receives the item with a link to the animation of the scaffolding with human voice over. If the learner chooses not to open the link and directly answers the item, it is effectively the same as the naive repetition. Unfortunately, the log does not track if the learner watches the video or if the learner finished the video. On aggregate, the video is played about 800 times. If each view is a by a separate id, the maximum exposure to the video treatment is about 30% of the treatment 2 group. The average watch time is about 47 seconds, out of the total length of 67 seconds.

The recruited users are randomly assigned with one of three item packets based on the remainder of their user id divided by 5: 0 is the control group, 2 vocabulary treatment, and 4 video treatment. The user id is randomly generated.

### Slack Identification

#### Log Data
The identification of the model hinges on the identification of the effort level. The effort level is not directly observed but has to be inferred from auxiliary data. The log data collected for the experiment includes the following fields:
(1) learner id

(2) question id

(3) Submit time

(4) time spent on the question (milliseconds)

(5) the grade (0-1)

(6) the actual answer in the text

Here is a sample of the original data log

```{r, echo=FALSE,message=FALSE,warning=FALSE}
knitr::kable(
  head(data%>%select(uid, eid, cmt_time, cmt_timelen,atag_pct, answers), 1), booktabs = TRUE,
  col.names = c('User ID', 'Item ID', 'Submit Time', 'Time Spent on Item', 'Score', 'Answers'),
  align='c',
  caption = 'Table 5.1: Demo data from the Log'
)
```

The time spent on the item is defined as the time elapsed between the time the server sends out the question to the learner's device and the time the  learner's submitted answer on the last subquestion received by the server. The transmission time in the network is negligible, usually in the magnitude of 10 milliseconds. The time spent does not distinguish how much time spent on each sub question and it is not a clean measure of student's active learning time. What student did between the question  presentation and the answer submission is not observed.

#### Answer Classifcation

The answers are initially classified into six categories:

(1) Blank answer: The learner submits nothing on the circumference and the area

(2) Slip: The answer is correctly calculated but the learner inputs in a wrong way

(3) Wrong Shape: The learner calculates correctly either the circumference or the area of the small rectangle

(4) Non-blank wrong answer: Neither circumference nor area is correctly calculated and not includes in the slip or the wrong shape category 

(5) right circumference: The learner correctly calculates the circumference of the large rectangle 

(6) right area: The learner correctly calculates the area of the large rectangle

(7) Correct Answer: Both circumference and area of the large rectangle are correctly calculated

The following table shows the summary statistics of different groups' answer composition on a different stage of the experiment. Appendix 2 shows a breakdown of the top answers in each category. Other than the non-blank wrong answer, all four error categories have clustered answer patterns: The top 5 answers cover over 50% of the answers. The category of the non-blank answer has a wide dispersion. The top non-blank answer for all but the pre-test item and the vocabulary scaffolding is the correct answer to the pre-test question, which occupies about 30% of the non-blank answer. Curiously, that is not the case for vocabulary scaffolding questions. In that question,  significantly more students provide the wrong shape answer. This is likely because the learner does not really read the question carefully and thus misunderstand the question.


```{r, echo=FALSE,message=FALSE,warning=FALSE}
ans_composition = data %>% group_by(group, qtype) %>% 
  summarize(blank = mean(blank_ans)*100,
            nonblank=mean(nonblank)*100,
            wrongshape=mean(wrong_shape)*100,
            rightcirc=mean(circ_right)*100,
            rightarea=mean(area_right)*100,
            slip=mean(is_slip)*100,
            correct=mean(score==1)*100)
knitr::kable(
  ans_composition %>% arrange(qtype,group), booktabs = TRUE,
  col.names=c('Group','Task','Blank Ans(%)','Non Blank Wrong Ans (%)', 'Wrong Shape(%)', 'Right Circ(%)', 'Right Area(%)','Slip(%)','Correct(%)'),
  align='c',
  caption = 'Table 5.2: Answer Composition'
)
```

#### Effort Classfication

The effort level is assumed to be a binary variable, slack or diligent. The blank answer and nonblank wrong answer is classified as slack. Right answer or partial right answer is defined as diligent. The classification of the wrong shape is tricky. In the initial question, the wrong shape is likely to be a diligent effort but refuse to correct it during the following practices. The wrong shape error is quite persistent. The odds ratio of making the same mistake conditional on wrong shape answer is 4:1. Therefore, the wrong shape in the pre-test is classified as diligent while in the subsequent items are slack. 

The summary statistics of the effort levels are presented as the following.


```{r, echo=FALSE,message=FALSE,warning=FALSE}
giveup_stat = data %>% group_by(group, qtype) %>% 
  summarize(slack = mean(giveup)*100, 
            deligent=mean(valid)*100,
            correct=mean(atag_pct==1)*100)
knitr::kable(
  giveup_stat %>% arrange(qtype,group), booktabs = TRUE,
  col.names=c('Group','Task','Slack Error (%)', 'Valid Error(%)','Correct(%)'),
  align='c',
  caption = 'Table 5.3: Effort Level Composition'
)
```

One way to check the validity of the classification is to look at the distribution of time spent on the item. In the pre-test, the distribution of the blank answer is not so left skewed compared to that in the later items. The learner may at least read through the question text before decides to drop it. In the subsequent items, except for the vocabulary scaffolding question, the learner submit a blank answer in such a short time that they give up so easily.

```{r,echo=FALSE,message=FALSE,warning=FALSE, fig.cap = "Distribution of Time Spent on Item by Error Types", fig.align='center'}
qplot(data=data %>% filter(cmt_timelen<=120), x=cmt_timelen, geom='density', col=etype, facets=group~qtype)+xlab('Time Spent on Task (Seconds)')
```

Remove the distribution of time spent on the blank answer from the analysis. The time distribution of valid effort is very similar to that of the correct answer, while that of the slack is skewed to the left. This is suggestive evidence that the non-blank answer indeed is the result of the effort slacking. Moreover, the time distribution of slackers is more skewed to the left in the subsequent items than that of the pre-test item, while the diligent curve does not move. This echoes the finding with the blank answer, which also suggests that the non-blank answer behaves just like the blank answer.


```{r,echo=FALSE,message=FALSE,warning=FALSE, fig.cap = "Distribution of Time Spent on Item by Error Types with treatment 1 of train", fig.align='center'}
qplot(data=data %>% filter(cmt_timelen<=120&!blank_ans), x=cmt_timelen, geom='density', col=etype, facets=group~qtype) + xlab('Time Spent on Task (Seconds)')

```

In general, the effort level is quite persistent. about 45% of the users always exert effort,about 20% of the users never do. Also, the chance of flipping is quite small. The probability of transit from slack to the effort is less than 15%.

```{r,echo=FALSE,message=FALSE,warning=FALSE, fig.cap = "Slack Pattern", fig.align='center'}
# Check the sequence dependence
wide_data=  data %>%
  select(uid,group,seq_id,giveup) %>%
  spread(seq_id,giveup)
names(wide_data) = c('uid','group','t1','t2','t3')

effort_persistence = merge(wide_data %>% group_by(group,t1,t2,t3) %>% summarize(n=n()), wide_data %>% group_by(group) %>% summarize(N=n())) %>% mutate(pct=n/N)

effort_persistence$pattern = '0,0,0'
effort_persistence$pattern[effort_persistence$t1&effort_persistence$t2&!effort_persistence$t3] = '1,1,0'
effort_persistence$pattern[effort_persistence$t1&!effort_persistence$t2&!effort_persistence$t3] = '1,0,0'
effort_persistence$pattern[effort_persistence$t1&!effort_persistence$t2&effort_persistence$t3] = '1,0,1'
effort_persistence$pattern[effort_persistence$t1&effort_persistence$t2&effort_persistence$t3] = '1,1,1'
effort_persistence$pattern[!effort_persistence$t1&!effort_persistence$t2&effort_persistence$t3] = '0,0,1'
effort_persistence$pattern[!effort_persistence$t1&effort_persistence$t2&!effort_persistence$t3] = '0,1,0'
effort_persistence$pattern[!effort_persistence$t1&effort_persistence$t2&effort_persistence$t3] = '0,1,1'


effort_persistence$pattern = factor(effort_persistence$pattern)

ggplot(data=effort_persistence, aes(x=pattern,y=pct, fill=group))+ geom_bar(stat = "identity",position="dodge") + xlab('Slack Pattern') + ylab('Frequency') + ggtitle('Frequency of the Slack Pattern: 1=Slack,0=Effort. Three Items (E1,E2,E3)')
```



## The result

### The learning curve
First show the learning curve and the slack curve (P(E_t=0)). 

```{r,echo=FALSE,message=FALSE,warning=FALSE, fig.cap = "The Learning Curve and the Slacking Curve| All Data", fig.align='center'}
all =  data %>% group_by(seq_id, group) %>% summarize(ypct=mean(score),yint=mean(y),gpct=mean(giveup))

y01 = qplot(data=all, x=seq_id, y =ypct, geom='line', col=group) + ggtitle('Learning Curve - Partial')+ xlab('Task') + ylab('Average')+scale_x_continuous(breaks=c(1,2,3),labels=c("Pre", "Train","Post"))

y02 = qplot(data=all, x=seq_id, y =yint, geom='line', col=group) + ggtitle('Learning Curve - Binary')+ xlab('Task') + ylab('Average')+scale_x_continuous(breaks=c(1,2,3),labels=c("Pre", "Train","Post"))
g0= qplot(data=all, x=seq_id, y =gpct, geom='line', col=group) + ggtitle('Slack Curve')+ xlab('Task') + ylab('Average')+scale_x_continuous(breaks=c(1,2,3),labels=c("Pre", "Train","Post"))


grid.arrange(y01,y02,g0, ncol=3)
```

If do a DID conditioning on the initial wrong, it is going to return a null result. Notice that the differential probability of slacking.

```{r,fig.cap = "The Learning Curve and the Slacking Curve| Wrong at PreTest", fig.align='center'}
non_placebo = data%>% filter(is_placebo==0) %>% group_by(seq_id, group) %>% summarize(ypct=mean(score),yint=mean(y),gpct=mean(giveup))

y11= qplot(data=non_placebo, x=seq_id, y =ypct, geom='line', col=group)+ggtitle("Learning Curve - Partial Grade")+ xlab('Task') + ylab('Average')+scale_x_continuous(breaks=c(1,2,3),labels=c("Pre", "Train","Post"))
y12 = qplot(data=non_placebo, x=seq_id, y =yint, geom='line', col=group)+ggtitle("Learning Curve - Binary Grade")+ xlab('Task') + ylab('Average')+scale_x_continuous(breaks=c(1,2,3),labels=c("Pre", "Train","Post"))
g1= qplot(data=non_placebo, x=seq_id, y =gpct, geom='line', col=group)+ggtitle("Slack Curve")+ xlab('Task') + ylab('Average')+scale_x_continuous(breaks=c(1,2,3),labels=c("Pre", "Train","Post"))

grid.arrange(y11,y12,g1, ncol=3)

```


Now Further conditions on the effective exposure to treatment. DID is going to return a postive result.
```{r,fig.cap = "The Learning Curve and the Slacking Curve| Wrong at PreTest and Exposure to Treatment", fig.align='center'}
non_placebo_retain = data%>% filter(is_placebo==0&is_retain==1) %>% group_by(seq_id, group) %>% summarize(ypct=mean(score),yint=mean(y),gpct=mean(giveup))


y21= qplot(data=non_placebo_retain, x=seq_id, y =ypct, geom='line', col=group)+ggtitle("Learning Curve - Partial Grade")+ xlab('Task') + ylab('Average')+scale_x_continuous(breaks=c(1,2,3),labels=c("Pre", "Train","Post"))
y22 = qplot(data=non_placebo_retain, x=seq_id, y =yint, geom='line', col=group)+ggtitle("Learning Curve - Binary Grade")+ xlab('Task') + ylab('Average')+scale_x_continuous(breaks=c(1,2,3),labels=c("Pre", "Train","Post"))
g2= qplot(data=non_placebo_retain %>% filter(seq_id!=2), x=seq_id, y =gpct, geom='line', col=group)+ggtitle("Slack Curve")+ xlab('Task') + ylab('Average')+scale_x_continuous(breaks=c(1,3),labels=c("Pre","Post"))



grid.arrange(y21,y22,g2, ncol=3)

```




### The DID results

The DID result is just like the figure, but with p-values and precision.

Conditions on initial failure, nothing.
```{r,echo=FALSE,message=FALSE,warning=FALSE,results='asis'}


y0data = data %>% filter(eid=='Q_10201056649366') %>% mutate(t=0)
y1pdata = data %>% filter(eid=='Q_10201056666357') %>% mutate(t=1)
y1sdata = data %>% filter(eid=='Q_10200351208705') %>% mutate(t=1)

ydata_p = rbind(y0data,y1pdata)
ydata_p = ydata_p %>% transform(d1=as.numeric(gid==2),d2=as.numeric(gid==4),d=as.numeric(gid!=0))
ydata_p = ydata_p %>% transform(dt=d*t,ddt =d2*t, d2t=d2*t,d1t=d1*t)

mod_1d = lm(data=ydata_p%>% filter(is_placebo==0),score~d1+d2+t+dt+ddt)
mod_2d = lm(data=ydata_p%>% filter(is_placebo==0),y~t+dt+ddt)

mod_1 = lm(data=ydata_p%>% filter(is_placebo==0),score~d1+d2+t+d1t+d2t)
mod_2 = lm(data=ydata_p%>% filter(is_placebo==0),y~t+d1t+d2t)

stargazer(mod_1, mod_2, mod_1d,mod_2d,
          header=FALSE,type='latex',
          dep.var.labels = 'Response',
          keep=c('d1t','d2t','dt','ddt'),
          covariate.labels=c('vocabulary','video','level','difference'),
          column.labels=c('pct','int','pct','int'),
          keep.stat=c("adj.rsq","n")
)

```


Check the error rate of subsequent items conditioning on initial success. Slip rate is negligible. The error rate is just the movement in effort level. The vocabulary treatment group has some problems while not the video treatment group.
```{r,echo=FALSE,message=FALSE,warning=FALSE,results='asis'}

mod_3 = lm(data=ydata_p %>% filter(is_placebo==1),score~d1+d2+t+d1t+d2t)
mod_4 = lm(data=ydata_p %>% filter(is_placebo==1),y~t+d1t+d2t)
mod_5 = lm(data=ydata_p %>% filter(is_placebo==1),giveup~d1+d2+t+d1t+d2t)


stargazer(mod_3, mod_4,mod_5,
          header=FALSE,type='latex',
          dep.var.labels = c('Response(pct)','Response(int)','Giveup'),
          keep=c('d1t','d2t'),
          covariate.labels=c('vocabulary','video'),
          keep.stat=c("adj.rsq","n")
)
```

Now conditions on effective exposure (no slacking at the train), return with positive result. 
```{r,echo=FALSE,message=FALSE,warning=FALSE,results='asis'}
mod_6d = lm(data=ydata_p%>% filter(is_placebo==0&is_retain==1),score~d1+d2+t+dt+ddt)
mod_7d = lm(data=ydata_p%>% filter(is_placebo==0&is_retain==1),y~t+dt+ddt)

mod_6 = lm(data=ydata_p%>% filter(is_placebo==0&is_retain==1),score~d1+d2+t+d1t+d2t)
mod_7 = lm(data=ydata_p%>% filter(is_placebo==0&is_retain==1),y~t+d1t+d2t)

stargazer(mod_6, mod_7, mod_6d,mod_7d,
          header=FALSE,type='latex',
          dep.var.labels = 'Response',
          keep=c('d1t','d2t','dt','ddt'),
          covariate.labels=c('vocabulary','video','level','difference'),
          column.labels=c('pct','int','pct','int'),
          keep.stat=c("adj.rsq","n")
)

```






### The MCMC results

MCMC result is essentially the same but not significant. The advantage of the video scaffolding is moderated because the conditional DID estimator has selection bias.

```{r,echo=FALSE,message=FALSE,warning=FALSE, fig.cap = "Distribution of Learning Rate", fig.align='center'}

params_effort_man = read.table(paste0(proj_dir,'/_data/03/chp3_parameter_chain_with_effort_manual.txt'), sep=',')
params_effort_auto = read.table(paste0(proj_dir,'/_data/03/chp3_parameter_chain_with_effort_auto.txt'), sep=',')
params_no_effort = read.table(paste0(proj_dir,'/_data/03/chp3_parameter_chain_no_effort.txt'), sep=',')

sample_idx = seq(300,1000,10)

lrate = data.frame(ctrl=params_effort_man$V23[sample_idx],treat1=params_effort_man$V24[sample_idx],treat2=params_effort_man$V25[sample_idx])
lrate = lrate %>% gather(group,val)
lrate$group = factor(lrate$group)
m1 = qplot(data=lrate, x=val, col=group, geom='density')+ggtitle('No Effort Choice')

lrate = data.frame(ctrl=params_effort_auto$V23[sample_idx],treat1=params_effort_auto$V24[sample_idx],treat2=params_effort_auto$V25[sample_idx])
lrate = lrate %>% gather(group,val)
lrate$group = factor(lrate$group)
m2 = qplot(data=lrate, x=val, col=group, geom='density')+ggtitle('Slack as Blank ans')

lrate = data.frame(ctrl=params_no_effort$V23[sample_idx],treat1=params_no_effort$V24[sample_idx],treat2=params_no_effort$V25[sample_idx])

lrate = lrate %>% gather(group,val)
lrate$group = factor(lrate$group)

m3 = qplot(data=lrate, x=val, col=group, geom='density')+ggtitle('Slack as Blank ans and Nonblank wrong answer')

grid.arrange(m3,m2,m1)
```






## Discussion and Future Work

## Appendix

### 1. Derivation of bias in the DID estimator

With the presence of effort, under the framework of no pain no gain, the probability of being learned in the second period is 

$$
P_E(X_2=1|D) = \pi+(1-\pi)\ell_D P(E_D)
$$
Under no effort assumption, the probability of being learned in the second period is 

$$
P(X_2|D) = \pi + (1-\pi)\ell_D
$$
The prbability of observing a right response in the post test is 

$$
\begin{aligned}
P_E(Y_2=1|D) &= [\pi+(1-\pi)\ell_D P(E)] (1-s) + [1-\pi-(1-\pi)\ell_D P(E)]g\\
P(Y_2=1|D) &= [\pi+(1-\pi)\ell_D] (1-s) + [1-\pi-(1-\pi)\ell_D]g
\end{aligned}
$$

The difference within group over time is thus

$$
P_E(Y_2=1) - P(Y_2=1) = (1-\pi)(1-P(E_D))\ell_D(s+g-1)
$$
The DID bias is thus 

$$
E(\hat{\gamma_E}) - E(\hat{\gamma}) = (1-\pi)(s+g-1)(\ell_1-\ell_1P(E_1)-\ell_0+\ell_0P(E_0))
$$



### 2. Breakdown of the answer category

**TODO:SUPPLY THE RIGHT ANSWER**

```{r, echo=FALSE,message=FALSE,warning=FALSE}
type_ans_stat = data %>% group_by(qtype, eid, ans_type, raw_ans) %>% summarize(n=n()) %>%
  group_by(qtype,eid,ans_type) %>% arrange(desc(n))


type_stat = data %>% group_by(qtype,eid, ans_type) %>% summarize(N=n())

ans_stat = merge(type_ans_stat, type_stat) %>% mutate(pct=n/N) %>%
  filter(ans_type %in% c('wrong shape', 'slip','non-blank ans', 'right area','right circumference')) %>%
  group_by(qtype,eid, ans_type) %>% arrange(qtype, eid, ans_type, desc(pct)) %>%
  mutate(cum_pct = cumsum(pct)) %>%
  mutate(idx = row_number()) %>% filter(idx<=5) %>%
  select(qtype,eid, ans_type, raw_ans,n, pct, cum_pct) %>% ungroup()
```


```{r,echo=FALSE,message=FALSE,warning=FALSE}

knitr::kable(
  ans_stat %>% filter(ans_type=='non-blank ans')%>% select(-ans_type) , booktabs = TRUE,
  caption = 'Answer Breakdown: Nonblank Answer'
)
```


```{r,echo=FALSE,message=FALSE,warning=FALSE}

knitr::kable(
  ans_stat %>% filter(ans_type=='wrong shape') %>% select(-ans_type) , booktabs = TRUE,
  caption = 'Answer Breakdown: Wrong Shape'
)
```


```{r,echo=FALSE,message=FALSE,warning=FALSE}

knitr::kable(
  ans_stat %>% filter(ans_type=='right area') %>% select(-ans_type) , booktabs = TRUE,
  caption = 'Answer Breakdown: Right Area'
)
```


```{r,echo=FALSE,message=FALSE,warning=FALSE}

knitr::kable(
  ans_stat %>% filter(ans_type=='right circumference') %>% select(-ans_type) , booktabs = TRUE,
  caption = 'Answer Breakdown: Right Circumference'
)
```


```{r,echo=FALSE,message=FALSE,warning=FALSE}

knitr::kable(
  ans_stat %>% filter(ans_type=='slip') %>% select(-ans_type) , booktabs = TRUE,
  caption = 'Answer Breakdown: Slip'
)
```
