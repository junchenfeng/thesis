---
output:
  pdf_document: default
  html_document: default
---

# Learning Through Practice {#model}

The ultimate goal of the Learning through Practice (LTP) model is the selection of a sequence of practice problems for the purpose of enhancing a learner's mastery. To achieve this goal, this chapter provides a learning model that defines practice efficacy and a statistical model to draw inference about it from observed data.

The focal parameter of the chapter is practice efficacy ($\ell$). Practice efficacy is defined as the probability that a learner reaches a higher level of mastery after attempting a practice item, or a practice problem, once. $\ell$ ranges between 0 and 1. When $\ell=1$, the practice efficacy is perfect, a learner achieves higher mastery for sure after one attempt. When $\ell=0$, the practice efficacy is null, a learner never achieves higher mastery no matter how much attempts she makes.  Practice items differ in their efficacy, which is the rationale for engineering item assignments ($A$) of a practice sequence.

Designed for this purpose, the Bayesian Knowledge Tracing model (BKT) model assumes the simplest structure for practice efficacy. It postulates that the mastery only has two states and learners are homogenous in their response to items. The BKT model masks key learner heterogeneities that are important to the understanding of the learning process and the engineering of an adaptive learning strategy. In contrast to BKT, this chapter assumes that there are more than two levels of mastery and learning rates differ depending on the mastery level, which is called state heterogeneity. This chapter also assumes that learners differ in their learning rate conditional on the same mastery level, which is called type heterogeneity. Formally, the LTP model postulates a learner's mastery level is an ordinal variable $X$, learner's type is a nominal variable $Z$, occasion within the practice sequence is a positive integer $t$ and the item id is a positive integer $j$. Practice efficacy expressed the probability of a learner of type $z$ ascends to mastery level $n$ from the base level $m$ after exposing to item $j$ as $\ell_j^{z;m,n}=P(X_t=n|X_{t-1}=m,Z=z,A_t=j)$.


The learning process can be defined in relation to the pedagogical efficacy and item assignments. In this thesis, it is characterized by the evolution of density of mastery levels over time, rather than the evolution of mastery levels per se. As long as practice items differ in their efficacies, a learning process cannot be defined without the knowledge of item assignment, because different orderings of items lead to different orderings of transition probabilities across values of $X$, and thus different densities, even given the same starting density. Formally, let the probability of a learner with type $z$ has mastery level $k$ at the first practice occasion be $\pi_1^{z;k} = P(X_1=k|Z=z)$. This is the prior belief of the learner mastery profile. Given the item assignments ($\mathbf{A}=\{A_1,\dots,A_T\}$), $\pi_{t,\mathbf{A}}^{z;n}$ be the desnity of a type $z$ learner with respect to the mastery level $n$ at occasion $t$ is:

$$
\pi_{t,\mathbf{A}}^{z;n} = \sum_{m=0}^{n} \pi_{t,\mathbf{A}-1}^{z;m} \ell_{A_t=j}^{z;m,n} \quad \forall t>1
$$


Had the mastery ($X$) and the learner type ($Z$) been observed, both initial density ($\pi^{z;k}_1$) and the practice efficacy ($\ell^{z;m,n}_j$) could be estimated from data. Unfortunately, neither of them is observed. The A statistical model is therefore needed to reveal it. The Hidden Markov Model (HMM) is a classical framework to describe such a dynamic latent variable model. The HMM model has two components: the hidden layer and the observed layer. The hidden layer describes the evolution of latent states in the form of a Markov Chain. The observed layer describes the generation of observed data based on latent states. 

The hidden layer consists of two elements, the initial density of latent states and the state transition matrix. In the context of the learning process, the initial density of the hidden layer is the prior belief of the density of a learner's initial mastery. The lower right diagonal of the state transition matrix is 0 because of the no-regression assumption. The upper right diagonal of the state transition matrix is filled with corresponding practice efficacy. 

The observed layer only involves the observed response  ($Y$) in the classical BKT model. This chapter expands the observed data to include learner engagement, which includes the stop decision ($H$) and the effort decision ($E$). The generation of the observed data ($O = \{Y,E,H\}$), which are discrete varibles, is specified as a multinomial distribution whose probability mass function depends on the latent mastery level $P(O|X=k)$. Importantly, when effort choice is involved, this thesis makes a critical assumption that "no pain no gain" which argues that a learner's mastery cannot be elevated unless she tries. Therefore, it also affects the evolution of the latent state. Let $E_t$ denote a learner makes a valid effort at occasion $t$, given the item assignments ($A$), the learning process is hence

$$
\pi_{t,\mathbf{A}}^{z;n} = \pi_{t-1,\mathbf{A}}^{z;n} + E_t\sum_{m=0}^{n-1} \ell^{z;m,k}_j\pi_{t-1,\mathbf{A}}^{z;m} \quad \forall t>1
$$




## Practice Efficacy and Learning Process

The core of the Learning Through Practice model (LTP) is practice efficacy. It characterizes the how practice items boost a learner's mastery. This section starts with a general definition built on an ordinal representation of mastery, then outlines the assumptions leading to a simplified working definition used in this thesis. 


### The General Definition of Efficacy

Let the mastery ($X_t$) at practice occasion $t$  be represented as a unidimensional ordered discrete variable with $M_x$ number of states. $M_x$ is a positive integer. In this thesis, it can take value either 2 or 3. $t \in \{1,2,\dots,T\}$, where $T$ is the max length of the practice sequence. The learning is not timed by clock time, but by the number of practice problems done, or the practice occasion. In the following analysis, "time" and "practice occasion" are used interchangeably.

The unidimensionality specification avoids the complexity of representing the response as a function of multiple inputs. If the latent mastery is multi-dimensional, the likelihood function of the observed response depends on the question being a single solution with sequential reasoning, multiple solutions with single step reasoning, or multiple steps with sequential reasoning. In addition, each reasoning can house one or more components of the mastery. The unidimensionality assumption also avoids the explosion of pedagogical efficacy parameters. If the latent mastery is multi-dimensional, the state transition matrix of one dimension is unlikely to be independent of all other dimensions. The number of the parameters of the transition matrix explodes exponentially as the dimension of the latent mastery grows.


In an ordinal mastery representation, learning can be defined as ascending from a lower level to a higher level. Practice efficacy is thus defined as the probability of such ascension. In addition to the learner type and mastery levels, a general definition of efficacy requires encoding the learning context, which includes item assignments, responses, and practice occasion. Let $j$ practice item id, $j \in \{1,2,\dots,J\}$, where $J$ is the total number of items in the question bank. Let $Y_t$ denote the observed response at practice occasion $t$, which can take value 0 or 1. Let $A_t$ denote the item assignment at practice occasion $t$. $A_t = j$ means that a learner encounters item $j$ at practice occasion $t$. Formally, the general efficacy can be written as

$$
\ell^{z;m,n}_{A_1,\dots,A_t;Y_1,\dots,Y_t;t} \equiv P(X_t=n|X_{t-1}=m; Z=z; A_1,\dots, A_t; Y_1,\dots,Y_t;t)
$$

An important assumption of the learning process is that a learner never regresses on mastery, or she never forgets what she has learned.

**Assumption 1:**

$$
\ell^{z;m,n}_{A_1,\dots,A_t;Y_1,\dots,Y_t;t} = 0 \quad \forall m > n
$$

### The Working Definition of Efficacy

The highly contextualized general definition of practice efficacy results in too many parameters to be estimated. For the sake of feasible inference, a working definition of practice efficacy needs to be decontextualised. In this thesis, the working definition is 

$$
\ell^{z;m,n}_{j} \equiv P(X_t=n|X_{t-1}=m; Z=z; A_t=j)
$$

Compared to the general definition, the working definition of the practice efficacy removes the dependencies on observed response ($Y_1,\dots,Y_t$), previous item assignments ($A_1,\dots,A_{t-1}$), and practice occasion ($t$). This subsection discusses the practical implications of these simplifications.

For a particular practice sequence with length $T$, denote the joint responses as $\mathbf{Y}_{1,T} = (Y_1,\dots,Y_T)$. Similarly,  $\mathbf{X}_{1,T}$ is the joint latent masteries, and $\mathbf{A}_{1,T}$  the joint item compositions. Let $\mathbf{y}_{1,T}=(y_1,\dots, y_T)$ be the realized response sequence and $P$ denotes the probability mass function where $P(\mathbf{Y}_{1,T}=\mathbf{y}_{1,T}) = P(Y_1=y_1,\dots, Y_T=y_T)$. Similary, $\mathbf{x}_{1,T}$ is the realized joint latent masteries, and $\mathbf{a}_{1,T}$  the realized joint item compositions. For simplicity, when referring to the whole practice sequence, the underscript $1,T$ is dropped throughout the thesis.

**Assumption 2**: Pedagogical efficacy does not depend on responses conditional on the previous latent mastery.

$$
\begin{aligned}
&P(X_t=n|X_{t-1}=m; Z=z; \mathbf{A}_{1,t-1}, A_t=j; \mathbf{Y}_{1,t-1}, Y_t,;t) \\
&= P(X_t=n|X_{t-1}=m;Z=z;\mathbf{A}_{1,t-1},A_t=j;t) \quad \forall \mathbf{Y}_{1,t-1}, Y_t
\end{aligned}
$$

It may strike some readers as odd to assume learner learns at the same rate whether or not she solves the problem or not. This is the exact critique of the performance factor analysis model (PFA) [@pavlik2009performance]. However, what stylized fact does the Assumption 2 fails to account for? The proponents of the PFA may argue that Assumption 2 does not generate a positive correlation between successes. This critique is not entirely correct because the successes are positive correlated unconditional on the latent mastery. More previous success implies higher mastery and consequently higher success rate in the future practice. Assumption 2 claims independence only after conditioning on the latent mastery.  The proponents of the PFA may be right to argue that Assumption 2 does not generate high enough positive correlation with an LTP model of binary latent mastery. However, a larger magnitude of the positive correlation may be achieved by allowing the latent mastery to have more states and a positive correlation between efficacy and the state of latent mastery. In short, the Assumption 2 greatly reduces the complexity of parameter learning without significantly impairs the model's explanatory power on a learning dataset.


**Assumption 3**: There is no complementarity or substitution effect in the item composition.
$$
\begin{aligned}
&P(X_t=n|X_{t-1}=m;Z=z;\mathbf{A}_{1,t-1},A_t=j;t)\\
&=P(X_t=n|X_{t-1}=m;Z=z;A_t=j;t) \quad \forall \mathbf{A}_{1,t-1}
 \end{aligned}
$$

Assumption 3 rules out scaffolding by preparing a learner with a string of easy problems to solve the final difficult problem. It also rules out a decreasing pedagogical efficacy in the case of naive repetition. If items in the sequence are nearly identical, the learner learns from subsequent practice opportunities with equal probability even if she does not learn from the first attempt.  


**Assumption 4**: The pedagogical efficacy is independent of the sequence position.

$$
\begin{aligned}
&P(X_t=n|X_{t-1}=m;Z=z;A_t=j;t)\\
&=P(X_t=n|X_{t-1}=m;Z=z;A_t=j) \quad \forall t
\end{aligned}
$$

Assumption 4 claims that a learner has the same probability of learning whether the item is the first one in the sequence or the last one. It essentially assumes that the learner is a paragon of grit and positive psychology. She is never frustrated by failures, never bored by repetition, and can focus as long as it takes.



### The Learning Process

For any particular learner, the learning process is characterized by the evolution of mastery levels, $\{X_1,X_2,\dots,X_T\}$. When two consecutive levels differ ($X_t \neq X_{t+1}$), learning happens. The thesis does not take this approach to characterize the learning process. For one thing, learning is a probabilistic event, therefore any particular realization of learning (or lack thereof) is a noisy signal of practice efficacy. For another thing, an analyst may be interested in mastery at the population levels for each type of learners. Instead, this thesis characterizes the learning process as a change of density of mastery levels over time. Let the probability of the "typical" learner of type $z$ has mastery level $k$ at practice occasion $t$ be $\pi_t^{z,k} = P(X_t=k|Z=z)$. Let the density of mastery for learner type $z$ at occasion $t$ be noted as $\mathbf{\Pi}^z_t = \{\pi_t^{z,0},\dots,\pi_t^{z,M_X-1}\}$ where $\sum_{k=0}^{M_x-1}\pi_t^{z,k}=1$ and $0\leq\pi_t^{z,k}\leq1$. The generic characterization of the learning process is $\mathbf{\Pi}^z_1,\dots,\mathbf{\Pi}^z_T$.

The generic characterization of the learning process masks the important role of item assignments. If practice efficacy is known, the expected learning process is deterministic in the sense that it can be expressed explicitly by the prior belief of the density of the initial mastery ($\mathbf{\Pi}^z_1$), practice efficacies ($\ell_j^{z;m,n}$) and item assignments ($\mathbf{A}=\{A_1,\dots,A_t\}$). In another word, given practice efficacies, it may be possible to formulate an item assignment $\mathbf{A^*}$ that is optimal to a particular learner's estimated mastery profile $\widetilde{\mathbf{\Pi}}^z_1$, which is the goal of the thesis.


Consider the learning process of a learner encountering item $j$ at practice occasion $t$. If her starting level of mastery is known for sure, say $m$, her new expected mastery profile can be expressed as 

$$
\begin{aligned}
\Pi^{z}_{t,j}&=P(X_t|X_{t-1}=n,A_t=j,Z=z)\\
&= \Bigg\{ \begin{array}{cc}
0 & \text{if }X_t<m \\
\ell^{z;m,X_t}_j & \text{if }X_t\geq m
\end{array}
\end{aligned}
$$

Instead, her exact mastery of level is unknown, but the density of her mastery is known. The probability that she reaches a higher mastery, say $n$, can be calculated by computing the joint likelihood of mastery at two states then integrating out the previous mastery. The tricky part is that the starting density depends on the previous item assignments $A_1,\dots,A_{t-1}$, except for the first practice occasion where the prior belief is employed. To save the notation from an abuse of symbols, this thesis simply notes the item assignment scheme as $\mathbf{A}$. The new density is therefore

$$
\begin{aligned}
\pi^{z,n}_{1,\mathbf{A}}&=\pi^{z,n}_1\\
\pi^{z,n}_{t,\mathbf{A}}&=\sum_{X_{t-1}}P(X_t=n,X_{t-1}|\mathbf{A}) \quad (\forall t>1)\\
&=\sum_{X_{t-1}}P(X_t=n|X_{t-1},A_t=j)P(X_{t-1}|\mathbf{A})\\
&=\sum_{k=0}^{n}\ell^{z;m,k}_j\pi^{z,k}_{t-1,\mathbf{A}} + \sum_{k=n+1}^{M_x-1}0\pi^{z,k}_{t-1,\mathbf{A}} \quad \text{(1.1)}\\
\end{aligned}
$$
The last term ($\sum_{k=n+1}^{M_x-1}0\pi^{z,k}_{t-1,\mathbf{A}}$) of equation (1.1) is implied by the no forgetting assumption.

### The Learning Process with Learner Engagement

One important aspect of the learner engagement is the effort decision ($E_t$), which is a binary variable. Motivated by the intuition of "no pain no gain", this thesis makes a strong that learning does not happen unless a learner actually tries  

**Assumption 5**: 
$$
\pi^{z,n}_{t,\mathbf{A}} = \pi^{z,n}_{t-1,\mathbf{A}}\quad\text{if } E_t=0
$$
With the addition of the effort decision, the full learning process can be described as 

$$
\begin{aligned}
\pi^{z,n}_{t,\mathbf{A}}
&= \Bigg\{ \begin{array}{cc}
\pi^{z,n}_1 & \text{if }t=1 \\
\pi_{t-1,\mathbf{A}}^{z;n} + E_t\sum_{m=0}^{n-1} \ell^{z;m,k}_j\pi_{t-1,\mathbf{A}}^{z;m} & \text{if }t>1
\end{array}
\end{aligned}
$$




## The Statistical Inference Model

Because the mastery of a learner is not directly observed but has to be inferred from observed data, this section develops a statistical model to make the inference. Hidden Markov model (HMM) is a classical framework that describes a dynamic latent process. The HMM has a hidden layer and an observed layer. The hidden Layer describes the evolution of the latent state while the observed layer describes the generation of observed data. The Bayesian Knowledge Tracing model is a special case of the HMM model. This thesis extends the BKT model in two ways: the introduction of learner heterogeneity and the inclusion of learner engagement. The extended model is named as Learning Through Practice model (LTP) to differentiate it from the BKT model.


### An Overview of Hidden Markov Model

Let the latent state be $S$, the observed data be $O$. Let the parameters of the hidden layer be $\Theta_S$, the parameters of the observed layer be $\Theta_O$. Let all the parameters be $\Theta=\{\Theta_S,\Theta_O\}$. The key challenge for HMM is to infer $P(\Theta_S,\Theta_O|O)$ when $S$ is not observed. The key insight HMM is that $S$ can first be augmented to produce full likelihood then be integrated out to get the posterior parameter distribution. 

Let $R_{\Theta}$ denote the parameter space of $\Theta$, $F(\Theta)$ denote the prior distribution of parameters. The HMM argues that posterior distribution of parameter$P(\Theta|O)$ can be obtained by

$$
\begin{aligned}
P(\Theta|O) &= \frac{P(O,\Theta)}{\int_{R_{\Theta}}P(O,\Theta)dF(\Theta)}\\
P(O,\Theta) &=\sum_SP(O,S,\Theta)
\end{aligned}
$$

Whereas the latent variable is sampled from the posterior distribution

$$
P(S|O,\Theta) = \frac{P(O,S,\Theta)}{P(O,\Theta)}
$$

Obviously, the augmented likelihood ($P(O,S,\Theta)$) plays a key role in the HMM scheme. It is the combined result of the hidden layer and the observed layer. The hidden layer is characterized by the joint likelihood $P(S,\Theta_S)$. It is usually factored as 

$$
P(S,\Theta_S) = P(S|\Theta_S)P(\Theta_S)
$$

where $P(S|\Theta_S)$ is informed by the theory about the hidden states while $P(\Theta_S)$ is the prior. The conditional likelihood $P(O|S,\Theta_O)$ characterizes the generation of the observed layer, where the dependence of $S$ is made explicit. The complete-data likelihood is thus

$$
P(O,S,\Theta) = P(O|S,\Theta_O)P(S|\Theta_S)P(\Theta)
$$
where $S$ is regarded as the mastery and learner type.

Here is a brief summary of the inference routine, which is described in much greater detail in Chapter Two:

(1) From prior parameter distribution sample $\hat{\Theta}$

(2) Intitialize the latent state $\hat{S}$ by $P(S|\Theta_S)$

(3) Sample new parameters $\hat{\Theta}'$ by  $P(\Theta|O)$

(4) Sample new latent states $\hat{S}'$ by $P(S|O,\Theta)$

(5) Repeat step (3)-(4) until converges

### Hidden Markov Model As A Learning Model

When applying the Hidden Markov model framework to the learning process, the latent states are the learner type and the learner mastery, while responses and other observed behavior are the observed data. The hidden layer describes the learning process or the evolution of latent mastery. The observed layer laid out the data generating process driven by the latent mastery. In the following analysis, the specific structure of $S,O,\Theta_S,\Theta_O$ will be laid out explicitly.



It should be noted that although the mastery is an ordinal variable, the statistical model for the hidden layer is a latent class model, rather than an ordered multinomial logit model. The ordered logit uses the ranking of the cutoff points of the continuous latent variable to impose the order while here the no-regression assumption (Assumption 1) imposes the order. Readers familiar with the literature of Item Response Theory (IRT) may also wonder why the latent mastery is not continuous. The different choices of operational definition are reflected in the shape of item characteristic curve (ICC). The ICC of the LTP model is a step function, whereas the ICC of the IRT model is a smooth sigmoid function. A priori, it is difficult to assert which ICC describes the true data generating process better. There are two scenarios in which the step function fits better. In the first scenario, the true mastery is a discrete variable and the true ICC is a step function. In the second scenario, the true mastery is a continuous variable but the true ICC is a mixture of sigmoid functions. In this case, a single sigmoid function may not fit as well as a flexible step function. As the number of discrete states increases, the step ICC will eventually outperform the single sigmoid ICC. Therefore, assuming the latent mastery as a discrete variable is not very restrictive as long as the number of states is allowed to vary.

### The Bayesian Knowledge Tracing Model

The BKT model is a special instance of the Hidden Markov model. To describe the latent state (mastery), the initial state density and the state evolution (efficacy) needs to specified. To describe the observed data (response), the observation matrix needs to be specified.


The BKT model adopts the simplest definition of practice efficacy possible. It only admits one learner type and two mastery states. Consequently, there exists one practice efficacy for each item $\ell_j^{1;0,1} = P(X_t=1|X_{t-1}=0,Z=1,A_t=j)$. For the rest of the thesis, denote the BKT efficacy as $\ell$, according to the convention. 

It is necessary to have a prior belief of the probability that a learner has mastery at the first practice occasion. Formally, such prior belief can be written as $\pi_1=P(X_1=1)$. $\pi_1$ is called prior knowledge in the learning analytics literature, but initial density in this thesis to be consistent with the Markov Chain Monte Carlo algorithm introduced in Chapter Three. Once $\pi$ and $\ell$ are known, the unconditional state density at each practice occasion $t$ can be recursively defined as 

$$
\pi_t = (1-\pi_{t-1})\ell + \pi_{t-1} \quad \forall t>1
$$

The inference of latent mastery is based on observed responses, $Y_1,\dots,Y_T$. The response of each practice occasion is a noisy measure of the concurrent mastery. The measure is noisy because a learner without mastery can answer correctly due to luck while a learner with mastery can answer incorrectly due to carelessness. The probability of a blind-luck correct is called guess rate, $g=P(Y_t=1|X_t=0)$. The probability of a careless incorrect is called slip rate $s=P(Y_t=0|X_t=1)$. 




In short, 

$$
\begin{aligned}
S & = \{X\}\\
O &= \{Y\}\\
\Theta_S &= \{\pi,\ell\}\\
\Theta_O &= \{s,g\}
\end{aligned}
$$


### Learner Heterogeneity

The efficacy of the BKT model is homogeneous for all learners given the same item. The LTP model allows an item to have different effects on different learners. The learner heterogeneity has already been built into the working definition of practice efficacy. One type of heterogeneity is state heterogeneity: Given the same type ($z$) and same mastery goal ($n$), learners from different starting mastery state ($k,m$) progress at different speeds. $\ell_j^{z,k,n}\neq\ell_j^{z;m,n}$. The other type of heterogeneity is type heterogeneity: Given the same origin ($m$) and same mastery goal ($n$), learners of different types ($z,z'$) progress at different speed.$\ell_j^{z,m,n}\neq\ell_j^{z';m,n}$.

The density of learner type is noted as $\alpha_z=P(Z=z)$, which sums up to 1. The generation of the observed response only depends on a learner's mastery level, not on her type. Intuitively, it means that learners at the same level produce similar responses, no matter how fast they get to that level. The observed response only takes value 0/1 in this thesis. The conditional probability of the observed response is

\begin{equation}
c^k_j \equiv P(Y_{t}=1|X_t=k,A_t=j) \label{eq:res_prob}
\end{equation}

For example, in the BKT model, $g_j = c_j^0$ and $s_j = 1-c_j^1$.


### Learner Engagement

So far, this chapter has implicitly assumed that the learner can engage in learning for as long as the instructor wishes and as focused as the learning task requires. Both the duration and the intensity of learner engagement are imperfect in a low stake learning environment, which is typical of most applications of the intelligent tutoring system. The learner engagement is not only another set of observed data that can be used to infer latent mastery, but engagement also influences the learning process directly. Therefore, it is important to include learner engagement as a component of the LTP model. This subsection includes two aspects of learner engagement: The stop decision describes the duration of learner engagement and the effort decision describes the intensity of learner engagement. 


#### Event Sequence

The addition of learner engagement makes the data generating process more complicated that the vanilla BKT process where only latent mastery and observed response are involved. The following event sequence clarifies the new learning process.

1. A learner is presented with a practice question.

2. The learner exerts a level of effort based on her state of latent mastery

3. The learner produces a response based on the effort level and her state of latent mastery. 

4. The learner receives feedback on the observed response.

5. If the learner has exerted effort, she learns probabilistically. Otherwise, she does not learn.

6. The learner can choose or be forced to exit. If the learner continues, repeat from (1); else data collection stops.


#### The Effort Decision

The effort ($E_t$) is assumed a binary choice with value 0 for not exerting effort and 1 for exerting effort. Conditional on the type of the learner, the state of latent mastery and the item id, the probability of exerting effort is constant.

\begin{equation}
\gamma_{j}^{z;k} \equiv P(E_t=1|Z=z, X_t=k, A_t=j) \label{eq:effort_prob}
\end{equation}


Furthermore, assume that if the learner does not exert effort, the response is always completely incorrect. 

**Assumption 6**: $P(Y_t=0|E_t=0,A_t=j) = 1  \quad \forall j,t$

#### The Stop Decision

The stop decision ($H_t$) denote whether a learner stop practice sequence at occasion $t$. $H_t=0$ means a learner continues to practice whiel $H_t=1$ means a learner is no longer practicing. The hazard rate of occasion $t$ ($\eta_t$) is the probability that a learner stops at occasion $t$ conditional on she continues at $t-1$. 

$$
\eta_t = P(H_t=1|H_{t-1}=0)
$$

Whether hazard rates depend on the response or the latent mastery merits a brief discussion. The issue is examined in details in Chapter Five. There are two types of stop decisions: stop-by-rule and stop-by-choice. An example of stop-by-rule is the "X-Strike" rule: A learner always keeps practicing unless she is forced to stop after accumulating X successes/failures. An example of stop-by-choice is the differential impact of boredom and frustration [@baker2010better]: A learner without mastery is frustrated by further practice while a learner with mastery is bored by it. In the case of stop-by-rule, the stop decision can only depend on the responses because they are what the system observes. In the case of stop-by-choice, the stop decision can reasonably depend on either the response or the latent mastery, but more likely the latter. Therefore, this thesis equates the stop-by-rule decision with a response dependent hazard model and the stop-by-choice decision with a mastery dependent hazard model. In the following analysis, Let the dependence states be $S$. $S =\{Z,X\}$ or $S=\{Y\}$.

This thesis assumes that the conditional hazard rate is independent of item characteristics. This is largely a by-product of the simple stop-by-rule accounting method: Most stop-by-rule decision weighs each correct or incorrect answer equally regardless of its item. A more nuanced item-dependent hazard function requires the knowledge of a specific learning product. For the sake of generalization, such feature is excluded from the LTP model    

**Assumption 7**: $P(H_t=1|H_{t-1}=0,S,A_t=j) = P(H_t=1|H_{t-1}=0,S,A_t=l)  \quad \forall j,l$


Furthermore, the functional form of hazard rate curve can be specified as parametric or nonparametric.  A nonparametric hazard function is analogous to that of the observed response or effort choice. A different parameter is assigned to the hazard rate of each state at each practice occasion. Formally, the nonparametric model postulates
\begin{equation}
\eta_t^s \equiv P(H_t=1|H_{t-1}=0,S_t=s) \label{eq:hr}
\end{equation}

In contrast, a parametric hazard function has one set of parameters for each state. The popular choice is the proportional hazard model, which allows for different base rates ($\lambda_s$) and different duration dependence ($\beta_s$) among states. 

$$
\eta_t^s\equiv \lambda_s e^{\beta_{s} t} 
$$

If the data generating process of the stop decision is parametric, both specifications are consistent but the parametric specification is efficient. Otherwise, the non-parametric specification is consistent while the parametric specification is inconsistent.




### LTP as HMM

The previous two subsections expand the BKT model to cover both learner heterogeneity and learner engagement. This subsection summarizes the LTP model in terms of the ingredients of the HMM model.

$$
\begin{aligned}
S & = \{X,Z\}\\
O &= \{Y,E,H,A\}\\
\Theta_S &= \{\pi,\ell,\alpha\}\\
\Theta_O &= \{c,\gamma,\eta\}
\end{aligned}
$$




### An Example of Input Data

Table \@ref(tab:inputsample) shows an example of the input data, which is used in Chapter Six. The first column is user id. The second column is item id. The third column is the practice occasion, which ranks the items into a sequence. The fourth column to the sixth column is observed data, responses, effort decisions and stop decisions respectively. The learner 30002 made a valid effort in the first item ($E_1=1$) but got it wrong ($Y_1=0$). She gave up on the second item ($Y_2=E_2=0$). However, she made an attempt for the third item and got it right ($E_3=Y_3=1$). The practice sequence is only three items long so the first two stop decision was no 0 ($H_1=H_2=0$) while the third stop decision was yes ($H_3=1$).

```{r,echo=FALSE,message=FALSE,warning=FALSE}

library(knitr)

showcase_data = data.frame(i=rep(30002,3),j=c('Q_10201056649366','Q_10201058056988','Q_10201056666357'),t=c(1,2,3),y=c(0,0,1),e=c(1,0,1),h=c(0,0,1))

kable(showcase_data, 
      col.names=c('User ID(i)','Item ID(j)','Occasion(t)','Response(Y)','Effort(E)','Stop(H)'),
      booktabs=T,align='c',format='pandoc',
      caption = '\\label{tab:inputsample} An Example of the LTP Input Data'
)

```

## Express Learning Theories with the LTP model

Because the LTP model relaxes the constraint of the restrictive structural representation of the Bayesian Knowledge Tracing model, it can have an arbitrary representation of the learning process, to the extent that the data allows for unique identification. To avoid abusing the LTP model as a pure data mining exercise, the representation of the learning process should be guided by learning theories. By the same token, because the LTP model is capable of expressing the testable implications of learning theories, the researcher can decide if the learning data fit her choice of the learning theory. Although this thesis does not carry out the empirical test, it is meaningful to point out the possibility of doing such test.


### Zone of Proximal Development

The zone of proximal development [@vygotsky1978interaction] postulates three types of relationship between the mental development of a learner and the mental requirement of a learning task. If the learner's mental development lags the mental requirement of the learning task, the learning is slow, the engagement is low, and the performance is poor. If the learner's mental development falls shorts of the requirement of the learning task if when she works independently but within her reach under the guidance or in collaboration, the learning speeds up, the engagement is high, and the performance improves. This is the zone of proximal development. If the learner's mental development exceeds the requirement of the task, the performance is high albeit there is no learning.

This theory naturally calls for a three-state latent mastery ($M_x=3$). It has empirically testable implications on the observed response and the effort rate. If the learner is not ready to learn ($X=0$), she will fail the problem with high probability, exert little effort, and has no chance to suddenly master the skill.

$$
\begin{aligned}
P(Y_t=0|X_t=0) &\approx 1\\
P(E_t=0|X_t=0) &\approx 1\\
P(X_t=2|X_{t-1}=0) &\approx 0\\
\end{aligned}
$$

If the learner has achieved mastery ($X=2$), she will not fail the problem completely.
$$
P(Y_t=0|X_t=2) \approx 0
$$

If the learner is in the zone of the proximal development ($X=1$), the learning process has no obvious constraints implied by Vygotsky's theory.


### Reinforcement Learning

The observation that people repeat actions that reward them with pleasure and avoid actions that punish them with pain is well-established in behavioral science. Reinforcement learning is not only a stylized fact of how we learn [@anderson2000learning] but may also be the biological foundation of how we learn [@holroyd2002neural]. In the context of learning through practice, reinforcement learning means that the more successes a learner get, the more engaged she is; the more failures a learner gets, the less engaged she is.

For the practice duration, if the stop decision depends on the latent mastery and the hazard rate is negatively correlated with the latent mastery, the LTP model generates the following pattern: The more successes the learner has in the preceding sequence, the more likely she is going to continue practice; the more failures the learner has in the preceding sequence, the less likely she is going to continue practice. This pattern arises because a higher rate of success implies a higher level of mastery, and consequently a lower probability to stop. 

The same is true for the practice intensity. If the effort rate is positively correlated with the latent mastery, unconditional on the latent mastery, the more success the learner has enjoyed, the more effort she is likely to put into practice; the more failures the learner has suffered, the less effort she is likely to exert. This pattern arises because a higher rate of success implies a higher level of mastery and consequently a higher probability to exert effort.


## Adaptive Practice Recommendation

The classical Bayesian Knowledge Tracing (BKT) model cannot generate adaptive practice recommendations within a knowledge/skill domain. This somewhat surprising result is a consequence of the homogeneous learning assumption imposed by the BKT model: If the learner has no mastery, she learns with a constant learning rate. If the learner has mastery, she does not learn. To highlight the problematic implication of this assumption, consider an extreme case that a college freshman and a first grader learn first order differentiation. According to the assumption of the BKT model, if both learners have not learned the skill, they learn at the same rate for any given material. 

This defect does not harm the Intelligent Tutoring Systems (ITSs) developed in the United States too much because major US ITSs focus on between domain objective individualization rather than within domain practice individualization. Use the math learning as an example. The ITS tries to sequence learning objectives that the learner needs to master in an optimal way. For instances, Khan Academy builds a knowledge tree and encourages learners to pass the test on parent nodes first before proceeding to their children nodes. The Cognitive Tutor follows a similar strategy to break a large learning goal into smaller skill-building blocks. Assessments and Learning in Knowledge Spaces (ALEKS) system adaptively changes the next learning objective given the learner's accomplished objectives. For objective individualization, the key question is what pre-requisite objectives the learner should achieve to ensure that the current objective is attainable [@doignon2012knowledge] and if such process does describe how people learn to acquire certain skills [@anderson2013language]. Within the learning objective, the practice question is usually generated by an algorithm rather than selected from a pre-existing content library. These computer-generated practice items are highly substitutable, thus the question is whether the practice engine is effective rather than which question the engine generated is most effective [@ritter2007cognitive]. Therefore, practice individualization within a knowledge domain is not the major concern for the learning analytics community.

However, for some education service providers, the main problem is not objective individualization but practice individualization. Consider the problem of helping a teacher compile a homework from an existing content pool. The learning objective sequencing is set by the teacher (or the curriculum), while the item sequencing is left to the algorithm. The BKT model family is not very useful for solving the item sequencing problem, so some service providers, such as Knewton, resort back to the literature of computerized adaptive testing, which may not be a good framework for instructional recommendations because it assumes no learning possible in the first place.

The LTP model addresses the problem of practice individualization by introducing learner's heterogeneous gain from practice. The construction of practice efficacy ($\ell^{z;m,n}_j$) defines two types of learner heterogeneity. The state heterogeneity refers to differential learning gains for learners with different levels of mastery conditional on the same learner type. The type heterogeneity refers to differential learning gains for learners with different types conditional on the same mastery level. Reconsider the previous "learning first order differentiation" example. With three levels of mastery inspired by Vygotsky's zone of proximal development, the first grader is defined as level-1 mastery who is not ready to learn, the college freshman is defined as level-2 mastery who is ready to learn but not proficient in the skill yet. The instruction has little efficacy on the level 1 learners but some efficacy on the level-2 learners. This is called state heterogeneity. For the college freshmen, some may be more versed in the mathematical reasoning than others, therefore the instruction may have different efficacies on learners with different susceptibilities. This is called type heterogeneity.

The learner engagement component of the LTP model introduces another dimension to practice individualization. Because item differs in its effort appeal condition on the type and the mastery state of the learner, there exists state heterogeneity and type heterogeneity in the effort appeal of the item as well. In general, the optimal practice item is both high in practice efficacy and strong in effort appeal. Heterogeneities on both aspects can give rise to a rich set of recommendation strategies.
